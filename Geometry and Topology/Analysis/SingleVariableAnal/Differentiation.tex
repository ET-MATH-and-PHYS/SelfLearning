%%%%%%%%%% Differentiation %%%%%%%%%%
\chapter{Differentiation}

\section{Introduction to Derivatives}


\begin{defn}[Differentiability]
    A function $f:\R\rightarrow \R$ is said to be \Emph{differentiable at $a$} if \begin{equation}
        \lim\limits_{h\rightarrow 0}\frac{f(a+h) - f(a)}{h}
    \end{equation}
    exists. In this case the limit is denoted by \Emph{$f'(a)$} and is called the \Emph{derivative of $f$ at $a$}. We also say that $f$ is \Emph{differentiable} if $f$ is differentiable at $a$ for all $a$ in its domain.
\end{defn}

\begin{defn}
    We define the \Emph{tangent line} to the graph of $f$ at $(a,f(a))$ to be the line through $(a,f(a))$ with slope $f'(a)$. That is, the tangent line at $(a,f(a))$ is well defined if and only if $f$ is differentiable at $a$.
\end{defn}


\begin{rmk}
    Given a function $f$, we denote by $f'$ the function whose domain is the set of all numbers $a \in \R$ such that $f$ is differentiable at $a$, and whose value at such a number $a$ is \begin{equation}
        \lim\limits_{h\rightarrow 0}\frac{f(a+h) - f(a)}{h}
    \end{equation}
    The function $f'$ is called the \Emph{derivative} of $f$.
\end{rmk}

\begin{nota}
    For a given function $f:\R\rightarrow \R$, the derivative $f'$ is often denoted by \begin{equation}
        \frac{df(x)}{dx}
    \end{equation}
    and the number $f'(a)$ is denoted by \begin{equation}
        \left.\frac{df(x)}{dx}\right\vert_{x=a}
    \end{equation}
\end{nota}


\begin{thm}
    If $f$ is differentiable at $a$, then $f$ is continuous at $a$.
\end{thm}
\begin{proof}
    Suppose $f$ is differentiable at a point $a$. Then we have that the limit $$\lim\limits_{h\rightarrow 0}\frac{f(a+h) - f(a)}{h}$$ exists. It follows by \ref{thm:limlaws} that \begin{align*}
        \lim\limits_{h\rightarrow 0}f(a+h) - f(a) &= \lim\limits_{h\rightarrow 0}\frac{f(a+h)-f(a)}{h}\cdot h \\
        &= \lim\limits_{h\rightarrow 0}\frac{f(a+h) - f(a)}{h}\cdot \lim\limits_{h\rightarrow 0} h\\
        &= f'(a)\cdot 0\\
        &= 0
    \end{align*}
    Thus, by \ref{thm:limlaws} the result that $\lim\limits_{h\rightarrow 0}f(a+h) - f(a) = 0$ is equivalent to $\lim\limits_{h\rightarrow 0}f(a+h) = \lim\limits_{h\rightarrow 0} f(a) = f(a)$. Thus, $f$ is continuous at $a$, replacing $a+h$ with $x$ and $h\rightarrow 0$ with $x \rightarrow a$.
\end{proof}


\begin{defn}[Higher Order Derivatives]
    Since the derivative of a function $f$ is also a function, we can take its derivative to obtain the function $(f')' = f''$. In general, we denote the $k+1$-th derivative of $f$ inductively by \begin{align*}
        f^{(1)} &= f' \\
        f^{(k+1)} &= (f^{(k)})'
    \end{align*}
    These are called \Emph{higher order derivatives of $f$}. We also define $f^{(0)} = f$. In Leibnitzian notation we write \begin{equation}
        \frac{d^kf(x)}{dx} = f^{(k)}
    \end{equation}
\end{defn}

\section{Differentiation Results}

\begin{thm}
    If $f$ is a constant function, $f(x) = c$, then $f'(a) = 0$ for all $a \in \R$.
\end{thm}
\begin{proof}
    Observe that for $a \in \R$, $$f'(a) = \lim\limits_{h\rightarrow 0}\frac{f(a+h)-f(a)}{h} = \lim\limits_{h\rightarrow 0}\frac{c-c}{h} = 0$$
    as desired.
\end{proof}


\begin{thm}
    If $f$ is the identity function, $f(x) = x$, then $f'(a) = 1$ for all $a \in \R$.
\end{thm}
\begin{proof}
    Observe that for $a \in \R$, $$f'(a) = \lim\limits_{h\rightarrow 0}\frac{f(a+h)-f(a)}{h} = \lim\limits_{h\rightarrow 0}\frac{a+h-a}{h} = \lim\limits_{h\rightarrow 0} 1 = 1$$
    as desired.
\end{proof}

\begin{thm}[Linearity]
    If $f$ and $g$ are differentiable at $a$, then $f+cg$ is differentiable for all $c \in \R$
\end{thm}
\begin{proof}
    Observe that \begin{align*}
        (f+cg)'(a) &= \lim\limits_{h\rightarrow 0}\frac{(f+cg)(a+h) - (f+cg)(a)}{h} \\
        &= \lim\limits_{h\rightarrow 0}\frac{f(a+h)+cg(a+h)-[f(a)+cg(a)]}{h} \\
        &= \lim\limits_{h\rightarrow 0}\frac{[f(a+h)-f(a)]+c[g(a+h)-g(a)]}{h} \\
        &= \lim\limits_{h\rightarrow 0}\left(\frac{f(a+h)-f(a)}{h}+c\frac{g(a+h)-g(a)}{h}\right) \\
        &= \lim\limits_{h\rightarrow 0}\frac{f(a+h)-f(a)}{h}+\lim\limits_{h\rightarrow 0}c\frac{g(a+h)-g(a)}{h} \\
        &= f'(a) + c\lim\limits_{h\rightarrow 0}\frac{g(a+h)-g(a)}{h} \\
        &= f'(a)+cg'(a) 
    \end{align*}
    as desired.
\end{proof}

\begin{thm}[Product Rule]
    If $f$ and $g$ are differentiable at $a$, then $f\cdot g$ is also differentiable at $a$ and $$(f\cdot g)'(a) = f'(a)\cdot g(a) + f(a) \cdot g'(a)$$
\end{thm}
\begin{proof}
    Observe that \begin{align*}
        (f\cdot g)'(a) &= \lim\limits_{h\rightarrow 0}\frac{(f\cdot g)(a+h) - (f\cdot g)(a)}{h} \\
        &= \lim\limits_{h\rightarrow 0}\frac{f(a+h)g(a+h) - f(a+h)g(a) + f(a+h)g(a) - f(a)g(a)}{h} \\
        &= \lim\limits_{h\rightarrow 0}\frac{f(a+h)[g(a+h)-g(a)]}{h} + \lim\limits_{h\rightarrow 0}\frac{g(a)[f(a+h) - f(a)]}{h} \\
        &= \lim\limits_{h\rightarrow 0}f(a+h)\cdot \lim\limits_{h\rightarrow 0}\frac{g(a+h) - g(a)}{h} + \lim\limits_{h\rightarrow 0}\frac{f(a+h)-f(a)}{h}\cdot \lim\limits_{h\rightarrow 0}g(a) \\
        &= f(a)\cdot g'(a) + f'(a)\cdot g(a)
    \end{align*}
    as claimed, where $\lim\limits_{h\rightarrow 0}f(a+h) = f(a)$ since $f$ is differentiable at $a$, which implies it is also continuous at $a$.
\end{proof}

\begin{thm}[Power Rule]
    IF $f(x) = x^n$ for some natural number $n$, then $$f'(a) = na^{n-1}$$ for all $a$.
\end{thm}
\begin{proof}
    For the proof we will proceed by induction on $n$. For $n = 1$ we have shown that $f'(a) = 1 = 1\cdot a^0$, satisfying the base case. Assume that there exists $k \in \N$ such that if $n = k$, $f'(a) = ka^{k-1}$. Then, for the case of $n = k+1$ we may write $g(x) = x\cdot x^k = I(x)\cdot f(x)$. Hence, by the product rule we have that for all $a$ \begin{align*}
        g'(a) &= (I\cdot f)'(a) \\
        &= I'(a) \cdot f(a) + I(a) \cdot f'(a) \\
        &= 1\cdot a^k + a\cdot ka^{k-1} \\
        &= (k+1)a^k
    \end{align*}
    as claimed. Hence, by mathematical induction we conclude that if $f(x) = x^n$ for $n \in \N$, then $f'(a) = na^{n-1}$ for all $a \in \R$.
\end{proof}


\begin{thm}[Derivative of a Quotient]
    If $g$ is differentiable at $a$, and $g(a) \neq 0$, then $1/g$ is differentiable at $a$ and $$\left(\frac{1}{g}\right)'(a) = \frac{-g'(a)}{|g(a)|^2}$$
\end{thm}
\begin{proof}
    Note that since $g$ is differentiable at $a$ it is continuous at $a$. Moreover, since $g(a) \neq 0$, there exists $\delta > 0$ such that $g(a+h) \neq 0$ for $|h| < \delta$. Therefore, $(1/g)(a+h)$ is well defined for small enough $h$, and we can write \begin{align*}
        \lim\limits_{h\rightarrow 0}\frac{(1/g)(a+h) - (1/g)(a)}{h} &= \lim\limits_{h\rightarrow 0}\frac{1/g(a+h) - 1/g(a)}{h} \\
        &= \lim\limits_{h\rightarrow 0}\frac{g(a) - g(a+h)}{h[g(a)\cdot g(a+h)]} \\
        &= \lim\limits_{h\rightarrow 0}\frac{-[g(a+h)-g(a)]}{h}\cdot \lim\limits_{h\rightarrow 0}\frac{1}{g(a)\cdot g(a+h)} \\
        &= -g'(a)\cdot \frac{1}{|g(a)|^2}
    \end{align*}
    where $\lim\limits_{h\rightarrow 0}1/g(a+h) = 1/g(a)$ by continuity of $g$.
\end{proof}

\begin{thm}[Quotient Rule]
    If $f$ and $g$ are differentiable at $a$ and $g(a) \neq 0$, then $f/g$ is differentiable at $a$ and $$(f/g)'(a) = \frac{g(a)\cdot f'(a) - f(a) \cdot g'(a)}{|g(a)|^2}$$
\end{thm}
\begin{proof}
    Note that $f/g = f\cdot (1/g)$, so we have \begin{align*}
        (f/g)'(a) &= (f\cdot 1/g)'(a) \\
        &= f'(a)\cdot(1/g)(a) + f(a)\cdot(1/g)'(a) \tag{Product Rule}\\
        &= \frac{f'(a)}{g(a)} -\frac{f(a)g'(a)}{|g(a)|^2} \tag{Quotient Derivative}\\
        &= \frac{f'(a)g(a) - f(a)g'(a)}{|g(a)|^2}
    \end{align*}
    as claimed.
\end{proof}

\begin{thm}[General Product Rule]
    If $f_1,f_2,...,f_n$ are differentiable at $a$ for some $n \in \N$, then $f_1\cdot f_2\cdot ...\cdot f_n$ is differentiable at $a$ and $$(f_1\cdot...\cdot f_n)'(a) = \sum\limits_{i=1}^nf_1(a)\cdot...\cdot f_{i-1}(a)\cdot f'_i(a)\cdot f_{i+1}(a)\cdot...\cdot f_n(a)$$
\end{thm}
\begin{proof}
    We proceed by induction on $n$. If $n = 1$ then $f_1'(a) = f_1'(a)$, so the base case holds. Now, suppose the claim is true for some $k \in \N$. Then it follows that if $n = k+1$ \begin{align*}
        (f_1\cdot ... \cdot f_k\cdot f_{k+1})'(a) &= (f_1\cdot ...\cdot f_k)'(a)f_{k+1}(a) + (f_1\cdot...\cdot f_k)(a)f_{k+1}'(a) \tag{Product Rule} \\
        &= \left[\sum\limits_{i=1}^kf_1(a)\cdot...\cdot f_{i-1}(a)\cdot f'_i(a)\cdot f_{i+1}(a)\cdot...\cdot f_k(a)\right]f_{k+1}(a)\\
        &+ f_1(a)\cdot ... \cdot f_k(a)\cdot f_{k+1}'(a) \tag{by Induction Hypothesis} \\
        &= \sum\limits_{i=1}^{k+1}f_1(a)\cdot...\cdot f_{i-1}(a)\cdot f'_i(a)\cdot f_{i+1}(a)\cdot...\cdot f_{k+1}(a)
    \end{align*}
    as desired. Thus by mathematical induction we conclude that the formula holds for all $n \in \N$.
\end{proof}

\begin{thm}[Chain Rule]
    If $g$ is differentiable at $a$ and $f$ is differentiable at $g(a)$, then $f\circ g$ is differentiable at $a$ and $$(f\circ g)'(a) = f'(g(a))\cdot g'(a)$$
\end{thm}
\begin{proof}
    Define a function $\phi$ as follows: \begin{equation}
        \phi(h) = \left\{\begin{array}{ll}
            \frac{f(g(a+h)) - f(g(a))}{g(a+h)-g(a)}, & \text{if } g(a+h)-g(a) \neq 0 \\
            f'(g(a)), & \text{if } g(a+h) - g(a) = 0
        \end{array}\right.
    \end{equation}
    Note that by differentiability of $g$ at $a$, $g$ is continuous at $a$ as well so as $h\rightarrow 0$, $g(a+h)-g(a)\rightarrow 0$, so if $g(a+h)-g(a)$ is not zero, then $\phi(h)$ will approach $f'(g(a))$ as $h$ goes to zero. If it is zero then $\phi(h)$ is exactly $f'(g(a))$. Note that as $f$ is differentiable at $g(a)$ we have $$\lim\limits_{k\rightarrow 0}\frac{f(g(a) + k) - f(g(a))}{k} = f'(g(a))$$
    Thus, if $\epsilon > 0$ there is some number $\delta' > 0$ such that, for all $k$, \begin{equation*}
        (1)\hspace{5pt}\text{if $0 < |k| < \delta'$, then } \left|\frac{f(g(a) + k) - f(g(a))}{k} - f'(g(a))\right| < \epsilon
    \end{equation*}
    Now, $g$ is differentiable at $a$, hence continuous at $a$, so there is $\delta > 0$ such that for all $h$, \begin{equation*}
        (2)\hspace{5pt}\text{if $|h| < \delta$, then } |g(a+h) - g(a)| < \delta'
    \end{equation*}
    Consider now any $h$ with $|h| < \delta$. If $k = g(a+h) - g(a) \neq 0$, then \begin{equation*}
        \phi(h) = \frac{f(g(a+h)) - f(g(a))}{g(a+h) - g(a)} = \frac{f(g(a)+k) - f(g(a))}{k}
    \end{equation*}
    it follows from $(2)$ that $|k| < \delta'$, and hence from $(1)$ that \begin{equation*}
        |\phi(h) - f'(g(a))| < \epsilon
    \end{equation*}
    On the other hand, if $g(a+h) - g(a) = 0$, then $\phi(h) = f'(g(a))$, so it is surely true that \begin{equation*}
        |\phi(h) - f'(g9a))| < \epsilon
    \end{equation*}
    We therefore have proved that \begin{equation*}
        \lim\limits_{h\rightarrow 0}\phi(h) = f'(g(a))
    \end{equation*}
    so $\phi$ is continuous at $0$. If $h \neq 0$, then we have $$\frac{f(g(a+h)) - f(g(a))}{h} = \phi(h)\cdot \frac{g(a+h)-g(a)}{h}$$
    even if $g(a+h)-g(a) = 0$. Therefore, we have that \begin{align*}
        (f\circ g)'(a) &= \lim\limits_{h\rightarrow 0}\frac{f(g(a+h)) - f(g(a))}{h} \\
        &= \lim\limits_{h\rightarrow 0}\phi(h)\cdot \lim\limits_{h\rightarrow 0}\frac{g(a+h)-g(a)}{h} \\
        &= f'(g(a))\cdot g'(a) 
    \end{align*}
    by continuity of $\phi(h)$ at $0$.
\end{proof}



\section{Applications of Derivatives}

\begin{defn}[Extrema]
    Let $f$ be a function and $A$ a set of numbers contained in the domain of $f$. A point $x \in A$ is \Emph{maximum point} for $f$ on $A$ if \begin{equation}
        f(x) \geq f(y) \forall y \in A
    \end{equation}
    The number $f(x)$ is itself called the \Emph{maximum value} of $f$ on $A$.

    A point $x \in A$ is a \Emph{minimum point} for $f$ on $A$ if \begin{equation}
        f(x) \leq f(y) \forall y \in A
    \end{equation}
    The number $f(x)$ is itself called the \Emph{minimum value} of $f$ on $A$.
\end{defn}


\begin{thm}\label{thm:dirext}
    Let $f$ be any function defined on $(a,b)$. If $x$ is an extremum point for $f$ on $(a,b)$, and $f$ is differentiable at $x$, then $f'(x) = 0$.
\end{thm}
\begin{proof}
    Consider the case where $f$ has a maximum at $x$. If $h$ is any number such that $x+h \in (a,b)$, then $$f(x) \geq f(x+h)$$
    since $f$ has a maximum on $(a,b)$ at $x$. This implies that $$f(x+h)-f(x) \leq 0$$
    Thus, if $h > 0$ we have that $$\frac{f(x+h) - f(x)}{h} \leq 0$$
    and consequently $$\lim\limits_{h\rightarrow 0^+}\frac{f(x+h)-f(x)}{h} \leq 0$$
    as otherwise $\frac{f(x+h) - f(x)}{h} > 0$ for some $h$, contradicting our initial assumptions. Similarly, if $h < 0$ we have $$\frac{f(x+h)-f(x)}{h} \geq 0$$
    so $$\lim\limits_{h\rightarrow 0^-}\frac{f(x+h)-f(x)}{h} \geq 0$$
    By hypothesis $f$ is differentiable at $x$, so these two limits must be equal, so in fact $f'(x) \leq 0$ and $f'(x) \geq 0$. Thus, $f'(x) = 0$.

    On the other hand, suppose $f$ has a minimum at $x$. Then $-f$ has a maximum at $x$. Indeed, for all $y \in (a,b)$ we have $f(y) \geq f(x)$, so $-f(y) \leq -f(x)$. Then, from our above argument and the differentiability of $f$ at $x$, we have $-f'(x) = 0$, which implies that $f'(x) = 0$.
\end{proof}


\begin{defn}[Local Extrema]
    Let $f$ be a function, and $A$ a set of numbers contained in the domain of $f$. A point $x$ in $A$ is a \Emph{local maximum [minimum] point} for $f$ on $A$ if there is some $\delta > 0$ such that $x$ is a maximum [minimum] point for $f$ on $A \cap(x-\delta,x+\delta)$.
\end{defn}


\begin{defn}
    A \Emph{critical point} of a function $f$ is a number $x$ such that \begin{equation}
        f'(x) = 0
    \end{equation}
    The number $f(x)$ itself is called a \Emph{critical value} of $f$.
\end{defn}

\begin{rmk}
    Give a function continuous $f$, if $x$ is an extrumum of $f$ on $[a,b]$, then one of the following must be satisfied: \begin{enumerate}
        \item $x$ is a critical point of $f$ in $[a,b]$
        \item $x = a$ or $x = b$ so $x$ is an endpoint of $[a,b]$
        \item $x$ is a point in $[a,b]$ such that $f$ is not differentiable at $x$
    \end{enumerate}
\end{rmk}


\begin{namthm}[Rolle's Theorem]\label{thmname:rol}
    If $f$ is continuous on $[a,b]$ and differentiable on $(a,b)$, and $f(a) = f(b)$, then there is a number $x \in (a,b)$ such that $f'(x) = 0$.
\end{namthm}
\begin{proof}
    It follows from continuity of $f$ on $[a,b]$ that $f$ has a maximum or minimum value on $[a,b]$ (by the Extreme Value Theorem).

    Suppose first that the maximum value occurs at a point $x \in (a,b0$. Then $f'(x) = 0$ by Theorem \ref{thm:dirext}. On the other hand suppose that the minimum value of $f$ occurs at some point $x$ in $(a,b)$. Then, again, $f'(x) = 0$ by Theorem \ref{thm:dirext}.

    Finally, suppose the maximum and minimum values both occur at the end points. Since $f(a) = f(b)$, the maximum and minimum values of $f$ are equal, so $f$ is a constant function, and for a constant function we can choose any $x \in (a,b)$ and have $f'(x) = 0$, completing the proof.
\end{proof}


\begin{namthm}[The Mean Value Theorem]\label{thmname:meanval}
    If $f$ is continuous on $[a,b]$ and differentiable on $(a,b)$, then there is a number $x \in (a,b)$ such that \begin{equation}
        f'(x) = \frac{f(b)-f(a)}{b-a} 
    \end{equation}
\end{namthm}
\begin{proof}
    Let \begin{equation*}
        h(x) = f(x) - \left[\frac{f(b) - f(a)}{b-a}\right](x-a)
    \end{equation*}
    Evidently, $h$ is continuous on $[a,b]$ and differentiable on $(a,b)$ as it is the sum of correspondingly continuous and differentiable functions. Moreover, \begin{align*}
        h(a) &= f(a) \\
        h(b) &= f(b) - \left[\frac{f(b) - f(a)}{b-a}\right](b-a) \\
        &= f(a)
    \end{align*}
    Consequently, we may apply \ref{thmname:rol} to $h$ and conclude that there exists $x \in (a,b)$ such that \begin{equation*} 
        0 = h'(x) = f'(x) - \frac{f(b)-f(a)}{b-a}
    \end{equation*}
    so that \begin{equation*}
        f'(x) = \frac{f(b) - f(a)}{b-a}
    \end{equation*}
    as desired.
\end{proof}

\begin{cor}
    If $f$ is defined on an interval and $f'(x) = 0$ for all $x$ in the interval, then $f$ is constant on the interval.
\end{cor}
\begin{proof}
    Let $a$ and $b$ be any two points in the interval with $a \neq b$. Then there is some $x \in (a,b)$ such that \begin{equation*}
        0 = f'(x) = \frac{f(b) - f(a)}{b-a}
    \end{equation*}
    so $f(b) - f(a) = 0$ and consequently $f(a) = f(b)$. Thus the value of $f$ at any two points in the interval is the same, so $f$ is constant on the interval.
\end{proof}

\begin{cor}
    If $f$ and $g$ are defined on the same interval, and $f'(x) = g'(x)$ for all $x$ in the interval, then there is come number $c$ such that $f = g+c$.
\end{cor}
\begin{proof}
    For all $x$ in the interval we have $(f-g)'(x) = f'(x) - g'(x) = 0$, so by the previous corollary there is some number $c$ such that $f-g = c$.
\end{proof}


\begin{defn}
    A function is \Emph{increasing} on an interval $I$ if $f(a) < f(b)$ whenever $a,b \in I$ with $a < b$. The function $f$ is \Emph{decreasing} on an interval $I$ if $f(a) > f(b)$ for all $a,b \in I$ with $a < b$.
\end{defn}


\begin{cor}
    If $f'(x) > 0$ for all $x$ in an interval, then $f$ is increasing on the interval; if $f'(x) < 0$ for all $x$ in the interval, then $f$ is decreasing on the interval.
\end{cor}
\begin{proof}
    Consider the case where $f'(x) > 0$. Let $a,b \in I$ with $a < b$. Then by \ref{thmname:meanval} there exists $x \in (a,b)$ such that \begin{equation*}
        f'(x) = \frac{f(b) - f(a)}{b-a}
    \end{equation*}
    But, $f'(x) > 0$ for all $x \in (a,b)$, so $$\frac{f(b) - f(a)}{b-a} > 0$$
    Since $b-a > 0$ we conclude that $f(b) > f(a)$ so $f$ is increasing.

    Next, consider the case for $f'(x) < 0$. Then $-f'(x) > 0$ for all $x \in I$, so by the first case we have that for all $a,b \in I$ with $a < b$, $-f(a) < -f(b)$. Multiplying both sides by $-1$ we have that $f(a) > f(b)$ for all $a,b \in I$ such that $a < b$, so $f$ is decreasing, as desired.
\end{proof}


\begin{thm}[Second Derivative Test]
    Suppose $f'(a) = 0$. If $f''(a) > 0$, then $f$ has a local minimum at $a$; if $f''(a) < 0$ then $f$ has a local maximum at $a$.
\end{thm}
\begin{proof}
    By definition \begin{equation*}
        f''(a) = \lim\limits_{h\rightarrow 0} \frac{f'(a+h) - f'(a)}{h}
    \end{equation*}
    Since $f'(a) = 0$ by assumption, we can write \begin{equation*}
        f''(a) = \lim\limits_{h\rightarrow 0}\frac{f'(a+h)}{h}
    \end{equation*}
    Suppose now that $f''(a) > 0$. Then there exists $\delta >0$ such that if $|h| < \delta$ $f'(a+h)/h > 0$. Thus, for $|h| < \delta$, if $h < 0$ we must have $f'(a+h) < 0$ and if $h > 0$ we must have $f'(a+h) > 0$. This means by our previous corollary that $f$ is increasing in the interval $(a,a+\delta)$, and decreasing in $(a-\delta, a)$. Thus, as $f'(a) = 0$, $f(a)$ must be a local minimum.

    If $f''(a) < 0$, then $-f''(a) > 0$ so $-f(a)$ is must be a local minimum. That is, there exists $\delta > 0$ such that if $x \in (a - \delta, a + \delta)$, then $-f(x) \geq -f(a)$. Hence, it follows that $f(x) \leq f(a)$ for all $x \in (a-\delta,a+\delta)$, so $f(a)$ is a local maximum of $f$.
\end{proof}


\begin{thm}
    Suppose $f''(a)$ exists. If $f$ has a local minimum at $a$, then $f''(a) \geq 0$; if $f$ has a local maximum at $a$, then $f''(a) \leq 0$.
\end{thm}
\begin{proof}
    Suppose $f$ has a local minimum at $a$. If $f''(a) < 0$ then by our previous result $f$ would have a local maximum at $a$. But, this implies that $f$ would be constant in some interval containing $a$, so that $f''(a) = 0$, which is a contradiction. Thus, we must have that $f''(a) \geq 0$.

    The case for a local maximum is analogous.
\end{proof}


\begin{thm}
    Suppose that $f$ is continuous at $a$, and that $f'(x)$ exists for all $x$ in some interval containing $a$, except perhaps for $x = a$. Suppose, moreover, that $\lim\limits_{x\rightarrow a}f'(x)$ exists. Then $f'(a)$ also exists and \begin{equation}
        f'(a) = \lim\limits_{x\rightarrow a}f'(x)
    \end{equation}
\end{thm}
\begin{proof}
    By definition \begin{equation*}
        f'(a) = \lim\limits_{h\rightarrow 0}\frac{f(a+h) - f(a)}{h}
    \end{equation*}
    For sufficiently small $h > 0$ the function $f$ will be continuous on $[a,a+h]$, and differentiable on $(a,a+h)$, by assumption (similarly for sufficiently small $h < 0$). By \ref{thmname:meanval} there is a number $\alpha_h \in (a,a+h)$ such that $$\frac{f(a+h) - f(a)}{h} = f'(\alpha_h)$$
    Now, $\alpha_h$ approaches $a$ as $h$ approaches $0$, because $\alpha_h$ is in $(a,a+h)$. Since $\lim\limits_{x\rightarrow a}f'(x)$ exists, it follows that $$f'(a) = \lim\limits_{h\rightarrow 0}\frac{f(a+h) - f(a)}{h} = \lim\limits_{h\rightarrow 0}f'(\alpha_h) = \lim\limits_{x\rightarrow a}f'(x)$$
    For this last equality write $\lim\limits_{x\rightarrow a}f'(x) = L \in \R$. Fix $\epsilon > 0$. Then there exists $\delta > 0$ such that for all $x \in (a-\delta, a+\delta)$, $|f'(x) - L| < \epsilon$. It follows that for $|h| < \delta$, if $h > 0$ and $\alpha_h \in (a,a+h) \subset (a-\delta,a+\delta)$ we have $|f'(\alpha_h) - L| < \epsilon$ and if $h < 0$ and $\alpha_h \in (a+h, a) \subset (a-\delta,a+\delta)$, then $|f'(\alpha_h) - L| < \epsilon$. Thus, by definition we have that $\lim\limits_{h\rightarrow 0^+}f'(\alpha_h) = \lim\limits_{h\rightarrow 0^-}f'(\alpha_h) = L$, so in particular $\lim\limits_{h\rightarrow 0}f'(\alpha_h) = L = \lim\limits_{x\rightarrow a}f'(x)$, completing the proof.
\end{proof}


\begin{namthm}[The Cauchy Mean Value Theorem]\label{thmname:caumeanval}
    If $f$ and $g$ are continuous on $[a,b]$ and differentiable on $(a,b)$, then there is a number $x \in (a,b)$ such that \begin{equation}
        [f(b) - f(a)]g'(x) = [g(b) - g(a)]f'(x)
    \end{equation}
\end{namthm}
\begin{proof}
    Let $$h(x) = f(x)[g(b) - g(a)] - g(x)[f(b)-f(a)]$$
    Then $h$ is continuous on $[a,b]$, differentiable on $(a,b)$, and $$h(a) = f(a)g(b) - g(a)f(b) = h(b)$$
    It follows by \ref{thmname:rol} that $h'(x) = 0$ for some $x \in (a,b)$, which implies that \begin{equation*}
        0 = h'(x) = f'(x)[g(b)-g(a)] - g'(x)[f(b) - f(a)]
    \end{equation*}
    completing the proof.
\end{proof}


\begin{namthm}[L'H\^{o}pital's Rule]
    Suppose that \begin{equation}
        \lim\limits_{x\rightarrow a}f(x) = 0\;and\;\lim\limits_{x\rightarrow a}g(x) = 0
    \end{equation}
    and suppose also that $\lim\limits_{x\rightarrow a}f'(x)/g'(x)$ exists. Then $\lim\limits_{x\rightarrow a}f(x)/g(x)$ exists, and \begin{equation}
        \lim\limits_{x\rightarrow a}\frac{f(x)}{g(x)} = \lim\limits_{x\rightarrow a}\frac{f'(x)}{g'(x)}
    \end{equation}
\end{namthm}
\begin{proof}
    The hypothesis that $\lim\limits_{x\rightarrow a}f'(x)/g'(x)$ exists contains two implicit assumptions: \begin{enumerate}
        \item there is an interval $(a-\delta,a+\delta)$ such that $f'(x)$ and $g'(x)$ exist for all $x \in (a - \delta, a + \delta)$, except, perhaps, $x = a$,
        \item in this interval $g'(x) \neq 0$, with the possible exception of $x = a$
    \end{enumerate}
    If we define $f(a) = g(a) = 0$, then $f$ and $g$ are continuous at $a$. If $x \in (a,a+\delta)$, then \ref{thmname:meanval} and \ref{thmname:caumeanval} apply to $f$ and $g$ on $[a,x]$ (a similar statement holds for $x \in (a-\delta, a)$). First, applying the \ref{thmname:meanval} to $g$, we see that $g(x) \neq 0$, for if $g(x) = 0$ there would exist $x_1 \in (a,x)$ with $g'(x_1) = 0$, contradicting 2.. Now, applying \ref{thmname:caumeanval} to $f$ and $g$, we see that there is a number $\alpha_x \in (a,x)$ such that \begin{equation*}
        [f(x)-0]g'(\alpha_x) = [g(x)-0]f'(\alpha_x)
    \end{equation*}
    or \begin{equation*}
        \frac{f(x)}{g(x)} = \frac{f'(\alpha_x)}{g'(\alpha_x)}
    \end{equation*}
    Now, let $\lim_{y\rightarrow a}f'(y)/g'(y) = L \in \R$. Fix $\epsilon > 0$. Then there exists $\delta' > 0$ such that if $y \in (a - \delta', a + \delta')$ then $|f'(y)/g'(y) - L| < \epsilon$. Then, for $x \in (a,a+\delta)$ (or $x \in (a-\delta, a)$) we have $(a,x) \subset (a-\delta, a+\delta)$ (or $(x,a) \subset (a-\delta, a+\delta$). Thus, for $|x-a| < \delta$ we have $\alpha_x \in (a,x) \subset (a -\delta, a+\delta)$ (or $\alpha_x \in (x,a) \subset (a-\delta,a+\delta)$), so $|f'(\alpha_x)/g'(\alpha_x) - L| < \epsilon$. Therefore, we conclude that \begin{equation*}
        \lim\limits_{x\rightarrow a^+} \frac{f'(\alpha_x)}{g'(\alpha_x)} = L = \lim\limits_{x\rightarrow a^-} \frac{f'(\alpha_x)}{g'(\alpha_x)} 
    \end{equation*}
    so in particular \begin{equation*}
        \lim\limits_{x\rightarrow a} \frac{f(x)}{g(x)} = \lim\limits_{x\rightarrow a} \frac{f'(\alpha_x)}{g'(\alpha_x)} =  \lim\limits_{y\rightarrow a} \frac{f'(y)}{g'(y)}
    \end{equation*}
    completing the proof.
\end{proof}


\subsection{Convexity}


\begin{defn}
    A function $f$ is \Emph{convex} on an interval $I$, if for all $a,b \in I$, the line segment joining $(a,f(a))$ and $(b,f(b))$ lies above the graph of $f$.

    This is equivalent to stating that for all $x \in (a,b)$, \begin{equation}
        \frac{f(x) - f(a)}{x-a} < \frac{f(b) - f(a)}{b-a}
    \end{equation}
\end{defn}


\begin{defn}
    A function $f$ is \Emph{concave} on an interval $I$, if for all $a,b \in I$, the line segment joining $(a,f(a))$ and $(b,f(b))$ lies below the graph of $f$.

    This is equivalent to stating that for all $x \in (a,b)$, \begin{equation}
        \frac{f(x) - f(a)}{x-a} > \frac{f(b) - f(a)}{b-a}
    \end{equation}
\end{defn}


\begin{thm}
    Let $f$ be convex. If $f$ is differentiable at $a$, then the graph of $f$ lies above the tangent line through $(a,f(a))$, except at $(a,f(a))$ itself. If $a < b$ and $f$ is differentiable at $a$ and $b$, then $f'(a) < f'(b)$.
\end{thm}
\begin{proof}
    If $0 < h_1 < h_2$, then $a < a+h_1 < a+h_2$, and applying $f$'s convexity we have that \begin{equation*}
        \frac{f(a+h_1) - f(a)}{h_1} < \frac{f(a+h_2)-f(a)}{h_2}
    \end{equation*}
    This implies that the values of $[f(a+h)-f(a)]/h$ decrease as $h\rightarrow 0^+$. Consequently, \begin{equation*}
        f'(a) < \frac{f(a+h)-f(a)}{h},h> 0
    \end{equation*}
    In fact, $f'(a)$ is the infimum of these numbers. Similarly, for $h$ negative, if $h_2 < h_1 < 0$, then \begin{equation*}
        \frac{f(a+h_1)-f(a)}{h_1} > \frac{f(a+h_2)-f(a)}{h_2}
    \end{equation*}
    This shows that the slope of the tangent line is greater that $[f(a+h)-f(a)]/h$ for $h < 0$. In fact, $f'(a)$ is the supremum of all these numbers, so $f(a+h)$ lies above the tangent line if $h < 0$. This satisfies the first part of the theorem. Now, suppose $a < b$. Then we have that \begin{equation*}
        f'(a) < \frac{f(a+(b-a)) - f(a)}{b-a} = \frac{f(b)-f(a)}{b-a}
    \end{equation*}
    since $b - a> 0$ and \begin{equation*}
        f'(b) > \frac{f(b+(a-b))-f(b)}{a-b} = \frac{f(a)-f(b)}{a-b} = \frac{f(b)-f(a)}{b-a}
    \end{equation*}
    since $a-b < 0$. Combining these inequalities we obtain $f'(a) < f'(b)$, as desired.
\end{proof}


\begin{lem}
    Suppose $f$ is differentiable and $f'$ is increasing. If $a < b$ and $f(a) = f(b)$, then $f(x) < f(a) = f(b)$ for $a < x < b$.
\end{lem}
\begin{proof}
    Suppose towards a contradiction that $f(x) \geq f(a) = f(b)$ for some $x \in (a,b)$. Then the maximum of $f$ on $[a,b]$ occurs at some point $x_0 \in (a,b)$ with $f(x_0) \geq f(a)$ and, of course, $f'(x_0) = 0$. On the other hand, applying \ref{thmname:meanval} to the interval $[a,x_0]$, we find that there is $x_1$ with $a < x_1 < x_0$ and \begin{equation*}
        f'(x_1) = \frac{f(x_0) - f(a)}{x_0 - a}\geq 0
    \end{equation*}
    contradicting the fact that $f'$ is increasing (since $f'(x_0) = 0$ and $x_1 < x_0$).
\end{proof}

\begin{thm}
    If $f$ is differentiable and $f'$ is increasing, then $f$ is convex.
\end{thm}
\begin{proof}
    Let $a < b$. Define $g$ by \begin{equation*}
        g(x) = f(x) - \frac{f(b) - f(a)}{b-a}(x-a)
    \end{equation*}
    It is easy to see that $g'$ is also increasing; moreover, $g(a) = g(b) = f(a)$. Applying the lemma to $g$ we conclude that $$a < x < b \implies g(x) < f(a)$$
    In other words, if $a < x < b$, then \begin{equation*}
        f(x) - \frac{f(b) - f(a)}{b-a}(x-a) < f(a)
    \end{equation*}
    or \begin{equation*}
        \frac{f(x) - f(a)}{x-a} < \frac{f(b) - f(a)}{b-a}
    \end{equation*}
    Hence, $f$ is convex.
\end{proof}


\begin{thm}
    If $f$ is differentiable and the graph of $f$ lies above each tangent line except at the point of contact, then $f$ is convex.
\end{thm}
\begin{proof}
    Let $a < b$. Since the tangent lien at $(a,f(a))$ is the graph of the function \begin{equation*}
        g(x) = f'(a)(x-a) + f(a)
    \end{equation*}
    and since $(b,f(b))$ lies above the tangent line, we have \begin{equation*}
        (1)\hspace{5pt}f(b) > f'(a)(b-a) + f(a)
    \end{equation*}
    Similarly, since the tangent line at $(b,f(b))$ is the graph of $h(x) =f'(b)(x-b) + f(b)$, and $(a,f(a))$ lies above the tangent line at $(b,f(b))$, we have \begin{equation*}
        (2)\hspace{5pt}f(a) > f'(b)(a-b) + f(b)
    \end{equation*}
    It follows from $(1)$ and $(2)$ that $f'(a) < f'(b)$. Then, from our previous theorem we have that $f$ is convex.
\end{proof}



\section{Inverse Functions}


\begin{defn}
    For any function $f$. the \Emph{inverse image} of $f$, denoted by $f^{-1}$, is the set of all pairs $(a,b)$ such that $(b,a) \in f$.
\end{defn}

\begin{rmk}
    $f^{-1}$ is a function if and only if $f$ is one-to-one.
\end{rmk}


\begin{thm}
    If $f$ is increasing (decreasing) on an interval $I$, then $f$ is injective on $I$ so $f^{-1}$ is a function and in fact $f^{-1}$ is increasing (decreasing).
\end{thm}
\begin{proof}
    Consider the case that $f$ is increasing. Then suppose $a,b \in I$ with $a \neq b$. Without loss of generality suppose $a < b$. Then since $f$ is increasing $f(a) < f(b)$ so in particular $f(a) \neq f(b)$. Therefore, $f$ is injective as claimed, so $f^{-1}$ is a well-defined function on $I$. Now, consider $a' < b'$ in $f(I) = I'$. Then there exist $x,y \in I$ such that $f(x) = a'$ and $f(y) = b'$, so in particular $f^{-1}(a') = x$ and $f^{-1}(b') = y$. Since $f$ is increasing and $f(x) = a' < b' = f(y)$ we must have that $x < y$. Thus, $f^{-1}(a') = x < y = f^{-1}(b')$, so $f^{-1}$ is increasing as claimed.

    Consider the case that $f$ is decreasing. Then $-f$ is increasing so it is injective and $-f^{-1}$ is increasing by the first case. Hence, we have that $f^{-1}$ is decreasing as desired.
\end{proof}


\begin{thm}
    If $f$ is continuous and one-to-one on an interval $I$, then $f$ is either increasing or decreasing on $I$.
\end{thm}
\begin{proof}
    We proceed in three steps:

    (1) If $a < b < c$ are three points in $I$, then I claim either $f(a) < f(b) < f(c)$ or $f(a) > f(b) > f(c)$. Indeed, suppose that $f(a) < f(c)$. If we have $f(b) < f(a)$, then the \ref{thmname:intval} applied to $[b,c]$ gives an $x \in (b,c)$ such that $f(x) = f(a)$, contradicting the fact that $f$ is injective on $[a,c]$. Similarly, if $f(b) > f(c)$ we would find a contradiction, so $f(a) < f(b) < f(c)$. Similar argumentation leads to the result that $f(a) > f(b) > f(c)$ in the second case.


    (2) If $a < b < c < d$ are four points in $I$, then I claim that either $f(a) < f(b) < f(c) < f(d)$ or $f(a) > f(b) > f(c) > f(d)$. Indeed we can apply (1) to $a<b<c$ and then to $b < c < d$.


    (3) Take any $a < b$ in $I$, and suppose $f(a) < f(b)$. Then $f$ is increasing, for if $c,d \in I$ are any two points, we can apply (2) to the collection $\{a,b,c,d\}$ after arranging them in increasing order.
\end{proof}


\begin{thm}
    If $f$ is continuous and one-to-one on an interval, then $f^{-1}$ is also continuous.
\end{thm}
\begin{proof}
    Since $f$ is continuous and injective on the interval, it is either increasing or decreasing. Consider the case that $f$ is increasing. We must show that \begin{equation*}
        \lim\limits_{x\rightarrow b}f^{-1}(x) = f^{-1}(b)
    \end{equation*}
    for each $b$ in the domain of $f^{-1}$. Such a number $b$ is of the form $f(a)$ for some $a$ in the domain of $f$. For any $\epsilon > 0$, we want to find a $\delta > 0$ such that for all $x$, if $x \in (f(a) - \delta, f(a) + \delta)$, then $|f^{-1}(x) - a| < \epsilon$, as $a = f^{-1}(b) = f^{-1}(f(a))$. Now, since $a-\epsilon < a <a+\epsilon$ we have that $f(a-\epsilon) < f(a) < f(a+\epsilon)$ since $f$ is presumed increasing. Let $\delta = \min(f(a+\epsilon)-f(a),f(a) - f(a-\epsilon))$. Our choice of $\delta$ ensures that $$f(a-\epsilon) \leq f(a) - \delta\;and\;f(a) + \delta \leq f(a+\epsilon)$$
    Consequently, if $$f(a) - \delta < x < f(a) + \delta$$ then $$f(a-\epsilon) < x < f(a+\epsilon)$$
    SInce $f$ is increasing, $f^{-1}$ is also increasing, and we obtain $$f^{-1}(f(a-\epsilon)) < f^{-1}(x) < f^{-1}(f(a+\epsilon))$$
    so $a-\epsilon < f^{-1}(x) < a+\epsilon$, which is precisely $|f^{-1}(x) - a| < \epsilon$, as desired.
\end{proof}


\begin{thm}
    If $f$ is a continuous one-to-one function defined on an interval $I$, and $f'(f^{-1}(a)) = 0$, then $f^{-1}$ is not differentiable at $a$.
\end{thm}
\begin{proof}
    We have $f(f^{-1}(x)) = x$. If $f^{-1}$ were differentiable at $a$, then the chain rule would imply that $$f'(f^{-1}(a))\cdot (f^{-1})'(a) = 1$$
    hence $$0\cdot (f^{-1})'(a) = 1$$
    which is impossible.
\end{proof}


\begin{thm}
    Let $f$ be a continuous one-to-one function defined on an interval $I$, and suppose that $f$ is differentiable at $f^{-1}(b)$, with derivative $f'(f^{-1}(b)) \neq 0$. Then $f^{-1}$ is differentiable at $b$, and \begin{equation}
        (f^{-1})'(b) = \frac{1}{f'(f^{-1}(b))}
    \end{equation}
\end{thm}
\begin{proof}
    Let $b = f(a)$. Then \begin{equation*}
        \lim\limits_{h\rightarrow 0}\frac{f^{-1}(b+h)-f^{-1}(b)}{h} = \lim\limits_{h\rightarrow 0}\frac{f^{-1}(b+h) - a}{h}
    \end{equation*}
    Now, every number $b+h$ in the domain of $f^{-1}$ can be written in the form $b+h = f(a+k)$ for a unique $k(h)$. Then \begin{align*}
        \lim\limits_{h\rightarrow 0}\frac{f^{-1}(b+h) - a}{h} &= \lim\limits_{h\rightarrow 0}\frac{f^{-1}(f(a+k(h)))-a}{f(a+k(h))-b} \\
        &= \lim\limits_{h\rightarrow 0}\frac{k(h)}{f(a+k(h))-f(a)}
    \end{align*}
    Since $b+h = f(a+k(h))$ we have $f^{-1}(b+h) = a+k(h)$, or $k(h) = f^{-1}(b+h)-f^{-1}(b)$. Now, since $f$ is continuous on $I$, $f^{-1}$ is also continuous on its domain, and in particular it is continuous at $b$. This means that $\lim\limits_{h\rightarrow 0}k(h) = 0$, so $k(h)$ goes to zero as $h$ goes to $0$. Hence, as $$\lim\limits_{k\rightarrow 0}\frac{f(a+k)-f(a)}{k} = f'(a) = f'(f^{-1}(b)) \neq 0$$ this implies that $f^{-1}$ is differentiable at $b$ and \begin{equation*}
        (f^{-1})'(b) = \frac{1}{f'(f^{-1}(b))}
    \end{equation*}
\end{proof}

\begin{subappendices}
    \section{Alternative Differentiation Formulation}

    \begin{defn}
        A function $f:(a,b)\subseteq \R\rightarrow \R$ (or $\C$) is said to be \Emph{differentiable} at $x \in (a,b)$ with derivative $f'(x)$ if the limit \begin{equation*}
            f'(x) = \lim\limits_{h\rightarrow 0}\frac{f(x+h) - f(x)}{h}
        \end{equation*}
        exists.
    \end{defn}

    If $f$ is differentiable at $x \in (a,b)$, it is immediate that $f$ is continuous at $x$. Indeed, let $\varepsilon > 0$. Then there exists $\delta > 0$ such that if $0 < |h| < \delta$, $\left|\frac{f(x+h)-f(x)}{h} - f'(x)\right| < \varepsilon$. Then let $\delta' = \min\left\{\delta, |f'(x)| + \varepsilon\right\}$. Then for $x+h \in B_{\delta'}(x)$, $h \neq 0$, we ahve \begin{equation*}
        |f(x+h) - f(x)| = |h|\left|\frac{f(x+h)-f(x)}{h}\right| < \delta'(|f'(x)| + \varepsilon) \leq \varepsilon
    \end{equation*}

    Now a useful equivalent condition to differentiability at $x \in (a,b)$ is the existence of a function $r(x,h)$ for $h$ close to $0$ such that $f(x+h) = f(x) + Dh + r(x,h)$ such that $\frac{r(x,h)}{h}\rightarrow 0$ as $h\rightarrow 0$, and then $D = f'(x)$. Indeed if $f$ is differentiable set $r(x,h) = f(x+h) - (f(x) + f'(x)h)$. On the other hand, if such an $r(x,h)$ exists, then $$\frac{f(x+h)-f(x)}{h} = \frac{r(x,h)}{h}+D\rightarrow D$$ so the limit exists and is $D$.

    \begin{defn}
        We say that $f$ is differentiable on $(a,b)$ if it is differentiable at all $x \in (a,b)$.
    \end{defn}

    \begin{prop}
        Let $f$ and $g$ be differentiable at $x$. Then \begin{itemize}
            \item $f\pm g$ is differentiable at $x$ with $(f\pm g)'(x) = f'(x)\pm g'(x)$ (additivity) 
            \item $fg$ is differentiable at $x$ with $(fg)'(x) = f'(x)g(x)+f(x)g'(x)$ (Liebnitz's rule) 
            \item If $g(y) \neq 0$ in a neighborhood of $x$, then $(1/g)$ is differentiable at $x$ with $(1/g)'(x) = -\frac{g'(x)}{g(x)^2}$
            \item For all $c \in \R$ $cf$ is differentiable at $x$ with $(cf)'(x) = cf'(x)$
        \end{itemize}
    \end{prop}
    \begin{proof}
        The first bullet is by linearity of limits. The second bullet follows from the computation \begin{equation*}
            \frac{(fg)(x+h) - (fg)(x)}{h} = \frac{(f(x+h)-f(x))g(x+h)}{h} + \frac{f(x)(g(x+h)-g(x)}{h}
        \end{equation*}
        and the fact that $g$ is continuous at $x$ and the product of limits is the limit of the product, if the limits involved all exist. The quotient also follows by a similar computation \begin{equation*}
            \frac{\frac{1}{g(x+h)} - \frac{1}{g(x)}}{h} = \frac{-(g(x+h)-g(x))}{hg(x+h)g(x)}
        \end{equation*}
        and the same properties of limits and $g$ at $x$. Finally, bullet follows simply by the calculation \begin{equation*}
            \frac{cf(x+h) - cf(x)}{h} = c\frac{f(x+h)-f(x)}{h}
        \end{equation*}
    \end{proof}

    Some basic derivatives from the definition are $f'(x) = 0$ if $f(x) = c\in\R$ is a constant, and later we shall show the converse also holds. Additionally, $id'(x) = 1$, for $id(x) = x$. Then by induction $\frac{d}{dx}x^n = nx^{n-1}$ for all $n = 0,1,2,3,...$.

    \begin{prop}
        If $f:(a,b)\rightarrow (\alpha,\beta)$ is differentiable at $x \in (a,b)$ and $g:(\alpha,\beta)\rightarrow \R$ is differentiable at $f(x) \in (\alpha,\beta)$, then $g\circ f$ is differentiable at $x$ with \begin{equation*}
            (g\circ f)'(x) = g'(f(x))f'(x)
        \end{equation*}
    \end{prop}
    \begin{proof}
        We use the remainder definition of differentiability to prove the claim. As $f$ is differentiable at $x$ we have $r_f(x,h)$ such that $f(x+h) = f(x) + f'(x)h + r_f(x,h)$, and as $g$ is differentiable at $f(x)$ we have $r_g(x,h)$ such that $g(f(x)+h) = g(f(x)) + g'(f(x))h + r_g(f(x),h)$. Then \begin{align*}
            g\circ f(x+h) &= g(f(x)+f'(x)h+r_f(x,h)) \\
            &= g(f(x)) + g'(f(x))(f'(x)h+r_f(x,h)) + r_g(f(x),\tilde{h}) \tag{$\tilde{h}:= f'(x)h+r_f(x,h)$} 
        \end{align*}
        Let $r_{g\circ f}(x,h) = g'(f(x))r_f(x,h) + r_g(f(x),\tilde{h})$. Then we have $\lim\limits_{h\rightarrow 0}g'(f(x))\frac{r_f(x,h)}{h} = 0$ and $\lim\limits_{h\rightarrow 0}\tilde{h} = 0$, so $$\lim\limits_{h\rightarrow 0}\frac{r_g(f(x),\tilde{h})}{h} = \lim\limits_{h\rightarrow 0}\frac{r_g(f(x),\tilde{h})}{\tilde{h}}\frac{\tilde{h}}{h} = 0\cdot f'(x) = 0$$ Thus, we have that $g\circ f$ is differentiable at $x$ with $(g\circ f)'(x) = g'(f(x))f'(x)$, as desired.
    \end{proof}

    \begin{prop}\label{prop:4.1.1}
        If $f:(a,b)\rightarrow \R$ and $x \in (a,b)$ such that \begin{equation*}
            f(x) \geq f(y) (\text{or }f(x) \leq f(y))\forall y \in (a,b)
        \end{equation*}
        then if $f$ is differentiable at $x$ it follows that $$f'(x) = 0$$
    \end{prop}
    \begin{proof}
        First, note that $$f'(x) = \lim\limits_{h\rightarrow 0}\frac{f(x+h)-f(x)}{h} = \lim\limits_{h\rightarrow 0^+}\frac{f(x+h) - f(x)}{h} = \lim\limits_{h\rightarrow 0^-}\frac{f(x+h)-f(x)}{h}$$ But for $h$ such that $x+h \in (a,b)$, and $h > 0$, we have $$\frac{f(x+h) - f(x)}{h} \leq 0 (\text{respectively } \geq 0)$$ while if $h < 0$, $$\frac{f(x+h) - f(x)}{h} \geq 0 (\text{respectively }\leq 0)$$ Thus, by order properties of limits $f'(x) \leq 0$ and $f'(x) \geq 0$, so $f'(x) = 0$.
    \end{proof}

    Next we explore a funcdamental result for differentiable functions on an interval, which we will use to prove the fundamental theorem of calculus.

    \begin{namthm}[Mean Value Theorem]
        Suppose $f$ is continuous on $[a,b]$ and is differentiable on $(a,b)$. Then there exists $\xi \in (a,b)$ such that $$f'(\xi) = \frac{f(b) - f(a)}{b-a}$$
    \end{namthm}
    \begin{proof}
        Consider $f(x) = f(x) - (x-a)\frac{f(b) - f(a)}{b-a}$. Then $g$ is continuous on $[a,b]$, differentiable on $(a,b)$, and $g(a) = f(a)$ while $g(b) = f(a)$ as well, so $\frac{g(b) - g(a)}{b-a} = 0$. Since $g$ is continuous on the compact set $[a,b]$, $g$ attains a maximum on $[a,b]$. If it occurs at $\xi \in (a,b)$, then $g'(\xi) = 0$. On the other hand, if the maximum occurs at $a$ or $b$, then since $g(a) = g(b) = \max_{[a,b]}g$, $g$ must attain its minimum in $(a,b)$. Thus, there exists $\zeta \in (a,b)$ such that $g(\zeta)$ is a minimum and $g'(\zeta) = 0$. Thus in either case we have a $\xi \in (a,b)$ such that $f'(\xi) - \frac{f(b)-f(a)}{b-a} = 0$, so $f'(\xi) = \frac{f(b) - f(a)}{b-a}$ as desired.
    \end{proof}


    \begin{namthm}[Inverse Function Theorem]
        Suppose $f$ is continuous on $[a,b]$ and differentiable on $(a,b)$, and there exists $\gamma_0,\gamma_1 \in \R$ such that $0 < \gamma_0 \leq f'(x) \leq \gamma_1 < \infty$ (or $-\infty < \gamma_0 \leq f'(x) \leq \gamma_1 < 0$) for all $x \in (a,b)$. Let $\alpha = f(a)$ and $\beta = f(b)$. Then there exists an inverse function $g:[\alpha,\beta]\rightarrow [a,b]$ (or $g:[\beta,\alpha]\rightarrow[a,b]$) which is continuous on $[\alpha,\beta]$ and differentiable on $(\alpha,\beta)$, with derivative \begin{equation*}
            (f^{-1})'(y) = g'(y) = \frac{1}{f'(g(y))} = \frac{1}{f'(f^{-1}(y))}
        \end{equation*}
        for all $y \in (\alpha,\beta)$.
    \end{namthm}
    \begin{proof}
        Let $x_1,x_2 \in [a,b]$, with $a \leq x_1 < x_2 \leq b$. By the mean value theorem there exists $\xi \in (x_1,x_2)$ such that $$f'(\xi) = \frac{f(x_2) - f(x_1)}{x_2-x_1}$$ This implies $$0 < \gamma_0 \leq \frac{f(x_2) - f(x_1)}{x_2-x_2} \leq \gamma_1 < \infty$$ so $$0<\gamma_0(x_2-x_1) \leq f(x_2) - f(x_1) \leq \gamma_1(x_2-x_1)$$ for all $a \leq x_1 < x_2 \leq b$. This implies that $f$ is strictly increasing, and so injective. Further, $f(x) \in [\alpha,\beta]$ for all $x \in [a,b]$ since $\alpha = f(a)$ and $\beta = f(b)$. By the intermediate value theorem it follows that $f$ is surjective onto $[\alpha,\beta]$. Since $f:[a,b]\rightarrow [\alpha,\beta]$ is a continuous bijection on a compact set, $f$ is a homeomorphism and $f^{-1}:[\alpha,\beta]\rightarrow [a,b]$ is also a homeomorphism. As $f$ is differentiable on $(a,b)$, there exists $r_f(x,h)$ satisfying certain properties discussed previously. Then for $y \in (\alpha,\beta)$, there exists $x \in (a,b)$ such that $f^{-1}(y) = x,$ so $f(x) = y$. Then \begin{align*}
            f^{-1}(y) + h = x+h = f^{-1}(f(x+h)) &= f^{-1}(f(x)+f'(x)h+r_f(x,h)) \\
            &= f^{-1}(y+f'(x)h+r_f(x,h))
        \end{align*}
        Let $\tilde{h} = f'(x)h+r_f(x,h)$, so $h = \frac{\tilde{h}}{f'(x)} - \frac{r_f(x,h)}{f'(x)}$. Then \begin{equation*}
            f^{-1}(y+\tilde{h}) = f^{-1}(y) + \frac{1}{f'(x)}\tilde{h} - \frac{r_f(x,h)}{f'(x)}
        \end{equation*}
        Recall $r_f(x,h) = f(x+h) - f(x) - f'(x)h$. Then let $r_g(x,\tilde{h}) = -\frac{[f(x+h) - f(x) - f'(x)h]}{f'(x)}$. Note $\gamma_0h + r_f(x,h) \leq \tilde{h} \leq \gamma_1 h + r_f(x,h)$, so $$\gamma_0+\frac{r_f(x,h)}{h} \leq \frac{\tilde{h}}{h} \leq \gamma_1 + \frac{r_f(x,h)}{h}$$ which implies $\frac{\tilde{h}}{h}$ and $\frac{h}{\tilde{h}}$ are bounded. Thus $$\frac{r_g(x,\tilde{h})}{\tilde{h}} = -\frac{1}{f'(x)}\frac{h}{\tilde{h}}\frac{r_f(x,h)}{h}$$ which goes to $0$ as $\tilde{h}$ goes to $0$, since $\tilde{h}\rightarrow 0$ implies $h\rightarrow 0$. Thus, $g=f^{-1}$ is differentiable at $y = f(x)$, and \begin{equation*}
            (f^{-1})'(y) = \frac{1}{f'(f^{-1}(y))}
        \end{equation*}
    \end{proof}

    The result for a negative derivative follows by replacing $f$ with $-f$.

    Note that if $f$ is differentiable in $(a,b)$ then $f'(x)$ is a function on $(a,b)$. If $f'(x)$ is differentiable at $x_0$ we may write \begin{equation*}
        f''(x_0) = \lim\limits_{h\rightarrow 0}\frac{f'(x_0+h)-f'(x_0)}{h}
    \end{equation*}
    and in general $f^{(k+1)}(x) = \frac{d}{dx}f^{(k)}(x)$, for all $k \in \N\cup\{0\}$.

    \begin{prop}\label{prop:4.1.4}
        If $f$ is differentiable on $(a,b)$ and $x_0 \in (a,b)$, $f'(x_0) = 0$ but $f''(x_0) > 0$, then there exists $\delta > 0$: $$f(x_0) < f(x),\;\;\forall x \in (x_0-\delta,x_0+\delta)\backslash \{x_0\}$$ We say that $f$ has a local minimum at $x_0$.
    \end{prop}
    \begin{proof}
        Note $$f''(x_0) = \lim\limits_{h\rightarrow 0}\frac{f'(x_0+h) - f'(x_0)}{h} > 0$$ Then there exists $\delta >0$ such that $\frac{f'(x_0+h) - f'(x_0)}{h} > 0$ for all $h \in [-\delta,\delta]$. In particular, as $f'(x_0) = 0$, $f'(x_0+h) > 0$ for $h \in (0,\delta]$ and $f'(x_0+h) < 0$ for $h \in [-\delta, 0)$. Consider $h \in (0,\delta]$. By the mean value theorem there exists $c \in (x_0,x_0+h)$ such that \begin{equation*}
            f(x_0+h) - f(x_0) = hf'(c) > 0
        \end{equation*}
        so $f(x_0) < f(x_0+h)$. If $h \in [-\delta,0)$, by the mean value theorem there exists $c \in (x_0+h,x_0)$ such that \begin{equation*}
            f(x_0+h) - f(x_0) = hf'(c) < 0
        \end{equation*}
        so $f(x_0) < f(x_0+h)$ again. Thus, for all $x \in (x_0 - \delta,x_0+\delta)\backslash\{x_0\}$, we have $f(x_0) < f(x)$.
    \end{proof}

    The result for a local maximum is then given by replacing $f$ by $-f$ in the previous result.

    \begin{prop}\label{prop:4.1.5}
        Suppose $f$ is twice differentiable on $(a,b)$ and $f''(x) > 0$ on $(a,b)$. Then for all $a < x_0 < x_1 < b$ and $\lambda \in (0,1)$, $$f(\lambda x_0+(1-\lambda)x_1) < \lambda f(x_0) + (1-\lambda)f(x_1)$$
    \end{prop}
    \begin{proof}
        Let $g(s) = sf(x_0) + (1-s)f(x_1) - f(sx_0+(1-s)x_1)$. Then $g(0) = f(x_1) - f(x_1) = 0$ and $g(1) = f(x_0) - f(x_0) = 0$. Note $g$ is also twice differentiable. Towards a contradiction suppose there exists $c \in (0,1)$ such that $g(c) < 0$. Since $g$ is continuous it attains its minimum, so there exists $s_0 \in (0,1)$ such that $g(s_0) \leq g(c) < 0$. Further, $g'(s_0) = 0$, where $g'(s) = f(x_0) - f(x_1) - f'(sx_0+(1-s)x_1)(x_0-x_1)$. Then $$f'(s_0x_0+(1-s_0)x_1) = \frac{f(x_1)-f(x_0)}{x_1-x_0}$$ and $g''(s) = -f''(sx_0 + (1-s)x_0)(x_0-x_1)^2 < 0$. In particular, $g''(s_0) < 0$, contradicting the fact that $g(s_0)$ is a minimum and Proposition \ref{prop:4.1.4}
    \end{proof}




\end{subappendices}


