%%%%%%%%%% Real Line %%%%%%%%%%
\chapter{Topology and Construction of the Real Line}\label{RealLineCons}
% use \chaptermark{}
% to alter or adjust the chapter heading in the running head


\section{Peano Arithmetic}

We begin by forming our number system from the ground up, starting wtih Giuseppe Peano's (1858-1932) axiomatized system for the natural numbers.

\begin{axiom}[Peano's Axioms]\index{Peano Arithmetic}
    Peano's system for the naturals consists of two central axioms: \begin{enumerate}
        \item Assume that there exists a set $\N$ and an element $0 \notin \N$. Define, notationally, $\tilde{\N} = \N\cup\{0\}$. Then, assume there exists an injective map $s:\tilde{\N}\rightarrow \N$ called the \Emph{successor function}
        \item \Emph{Mathematical Induction}: Whenever a subset $S \subseteq \tilde{\N}$ satisfies $0 \in S$, and if $k \in S$ then $s(k) \in S$, then this implies $S = \tilde{\N}$. Notationally we have $$(0 \in S \land (k \in S \implies s(k) \in S)) \implies S = \tilde{\N}$$
    \end{enumerate}
\end{axiom}

Given these axioms, we can define an addition operation on $\tilde{\N}$:
\begin{definition}\index{Binary Operation}
    We define the binary operation $+:\tilde{\N}\times\tilde{\N}\rightarrow\tilde{\N}$ inductively for $x,y \in \tilde{\N}$ by stating \begin{enumerate}
        \item $x + 0 = x$ 
        \item $x + s(y) = s(x+y)$ 
    \end{enumerate}
\end{definition}

The definition is performed inductively, or recursively. Fix $x \in \tilde{\N}$ and let $S = \{y \in \tilde{\N}:x+y\text{ is defined}\}$. By definition $0 \in S$. Further, if $y \in S$, $x+y$ is defined in $\tilde{\N}$, so $x+s(y) := s(x+y)$. Since $x+y \in \tilde{\N}$, by axiom 1 of Peano's arithmetic $s(x+y) \in \N\subset \tilde{\N}$. Thus, $s(x+y)$ is defined so $s(y) \in S$. Hence by mathematical induction $S = \tilde{\N}$ so $+$ is a well defined binary operation for all $x,y \in \tilde{\N}$.

We can similarly define multiplication:

\begin{definition}\index{Successor}
    We define the binary operation $\cdot:\tilde{\N}\times\tilde{\N}\rightarrow\tilde{\N}$ inductively for $x,y \in \tilde{\N}$ by stating \begin{enumerate}
        \item $x \cdot 0 = 0$ 
        \item $x \cdot s(y) = x\cdot y + x$ 
    \end{enumerate}
\end{definition}

This defines $x\cdot y$ inductively as in the case of $+$. Now, we define our unit:
\begin{definition}
    We define $1 \in \N$ by $1 := s(0)$.
\end{definition}

Now we can derive many of the standard properties of the naturals.

\begin{proposition}\label{prop:1.1.1}
    For all $x \in \tilde{\N}$, $x+1 = s(x)$.
\end{proposition}
\begin{proof}
    Let $x \in \tilde{\N}$. Then $x + 1 = x+s(0)$, but then by our inductive definition for $+$, $x+s(0) = s(x+0)$, and $x+0 = x$ by definition, so $$x+1 = s(x)$$
\end{proof}

\begin{proposition}\label{prop:1.1.2}
    For all $x \in \tilde{\N}$, $0+x = x$.
\end{proposition}
\begin{proof}
    We proceed by induction on $x \in \tilde{\N}$. If $x = 0$, then $0 + 0 = 0 = x$, by definition. Suppose inductively that we have $x \in \tilde{\N}$ such that $0+x=x$. Then $0+s(x) = s(0+x)$. But, $0+x = x$ by the induction hypothesis, so $0+s(x) = s(x)$ and our result holds for $s(x)$. Thus, by mathematical induction we conclude that $0+x = x$ for all $x \in \tilde{\N}$.
\end{proof}

\begin{proposition}\label{prop:1.1.3}
    For all $x,y \in \tilde{\N}$, $s(y) + x = s(y+x)$.
\end{proposition}
\begin{proof}
    Let $y \in \tilde{\N}$, and we proceed by induction on $x \in \tilde{\N}$. If $x = 0$ then $s(y)+0 = s(y)$, and $s(y+0) = s(y)$, so the base case holds. Now, suppose the proposition holds for some $x \in \tilde{\N}$. Then $s(y) + s(x) = s(s(y) + x)$ by definition, and by the induction hypothesis $s(y) + x = s(y+x) = y+s(x)$ by definition. Thus, $s(y)+s(x) = s(y+s(x)$, as desired. Thus, by mathematical induction we conclude taht $s(y) + x = s(y+x)$ for all $x,y \in \tilde{\N}$.
\end{proof}

\begin{proposition}\label{prop:1.1.4}
    For all $x, y \in \tilde{\N}$, $x+y = y+x$ (Commutative Law).
\end{proposition}
\begin{proof}
    Fix $x \in \tilde{\N}$, and we proceed by induction on $y \in \tilde{\N}$. If $y = 0$ then $x+0 = x$ by definition, and $0+x = x$ by Proposition \ref{prop:1.1.2}, so the base case holds. Now, suppose the proposition holds for some $y \in \tilde{\N}$. Then $x+s(y) = s(x+y)$ by definition, and by Proposition \ref{prop:1.1.3} we have $s(y)+x = s(y+x)$. By the induction hypothesis $x+y = y+x$, so $s(x+y) = s(y+x)$, and it follows that $s(y)+x = x+s(y)$. Hence, as $x$ was arbitrary, we have by mathematical induction that $x+y = y+x$ for all $x,y \in \tilde{\N}$.
\end{proof}

\begin{proposition}\label{prop:1.1.5}
    For all $x,y,z \in \tilde{\N}$, $x+(y+z) = (x+y)+z$ (Associative Law).
\end{proposition}
\begin{proof}
    Fix $x,y \in \tilde{\N}$, and proceed by mathematical induction on $z \in \tilde{\N}$. If $z = 0$, $x+(y+0) = x+y = (x+y)+0$, so the base case holds. Suppose the proposition holds for some $z \in \tilde{\N}$. Then it follows that \begin{align*}
        x+(y+s(z)) &= x + s(y+z) = s(x+(y+z)) \\
        &= s((x+y)+z) \tag{by Induction Hypothesis} \\
        &= (x+y)+s(z)
    \end{align*}
    as desired. Thus by the axiom of mathematical induction we have our result.
\end{proof}

\begin{proposition}\label{prop:1.1.6}
    For all $x \in \tilde{\N}$, $x\cdot 1 = x$.
\end{proposition}
\begin{proof}
    Fix$ x \in \tilde{\N}$. Then $x\cdot 1 = x\cdot s(0) := x\cdot 0 + x = 0 + x = x$, by Proposition \ref{prop:1.1.4}.
\end{proof}

\begin{proposition}\label{prop:1.1.7}
    For all $x \in \tilde{\N}$, $0\cdot x = 0$.
\end{proposition}
\begin{proof}
    We proceed by induction on $x \in \tilde{\N}$. If $x = 0$, $0\cdot 0 = 0$ by definition. If $0\cdot x = 0$ for some $x \in \tilde{\N}$, then $0 \cdot s(x) = 0\cdot x + 0 = 0$, so by mathematical induction we have our result.
\end{proof}

\begin{proposition}\label{prop:1.1.8}
    For all $x,y \in \tilde{\N}$, $s(x)\cdot y = x\cdot y + y$.
\end{proposition}
\begin{proof}
    Fix $x \in \tilde{\N}$, and proceed by induction on $y \in \tilde{\N}$. If $y = 0$, $s(x)\cdot 0 = 0 = x\cdot 0 + 0$. Suppose the result holds for some $y \in \tilde{\N}$. Then $s(x)\cdot s(y) = s(x)\cdot y + s(x)$ by definition, and $s(x)\cdot y = x\cdot y + y$ by the induction hypothesis. By Proposition \ref{prop:1.1.5}, $(x\cdot y+y)+s(x) = x\cdot y + (y+s(x)) = x\cdot y + s(y+x)$. By Proposition \ref{prop:1.1.4}, $x\cdot y + s(y+x) = x\cdot y + s(x+y) = x\cdot y + (x+s(y))$. Finally, by Proposition \ref{prop:1.1.5} again we have $x\cdot y + (x+s(y)) = (x\cdot y + x) + s(y) = x\cdot s(y)+s(y)$, as desired. The result follows by the principle of mathematical induction.
\end{proof}

\begin{proposition}\label{prop:1.1.9}
    For all $x,y \in \tilde{\N}$, $x\cdot y = y\cdot x$.
\end{proposition}
\begin{proof}
    Fix $x \in \tilde{\N}$, and proceed by mathematical induction on $y \in \tilde{\N}$. If $y = 0$, $x \cdot 0 = 0 = 0\cdot x$ by Proposition \ref{prop:1.1.7}, so the base case holds. Suppose it holds for some $y \in \tilde{\N}$. Then $x\cdot s(y) = x\cdot y + x = y\cdot x + x$ by the induction hypothesis, and by Proposition \ref{prop:1.1.8}, $y\cdot x + x = s(y)\cdot x$. Thus by mathematical induction we have commutivity of multiplication.
\end{proof}

\begin{proposition}\label{prop:1.1.10}
    For all $x,y,z \in \tilde{\N}$, $(x+y)\cdot z = x\cdot z + y \cdot z$ (Distributivity).
\end{proposition}
\begin{proof}
    Fix $x,z \in  \tilde{\N}$ and proceed by induction on $y \in \tilde{\N}$. If $y = 0$, $(x+0)\cdot z = x\cdot z = x\cdot z + 0\cdot z$ by Proposition \ref{prop:1.1.7}. Suppose it holds for some $y \in \tilde{\N}$. Then $(x+s(y))\cdot z = s(x+y)\cdot z = (x+y)\cdot z + z$ by Proposition \ref{prop:1.1.8}. By the induction hypothesis, associativity, and the same proposition again we have $$(x+y)\cdot z + z = (x\cdot z + y \cdot z) + z = x\cdot z + (y\cdot z + z) = x\cdot z + s(y)\cdot z$$
    as desired. Thus we have distributivity of multiplication by mathematical induction.
\end{proof}

\begin{proposition}\label{prop:1.1.11}
    For all $x,y,z \in \tilde{\N}$, if $x+z = y+z$, then $x = y$.
\end{proposition}
\begin{proof}
    Let $x,y \in \tilde{\N}$, and we proceed by induction on $z \in \tilde{\N}$. If $z = 0$, $x+0 = y+0$ implies $x = y$, so the base case holds. If it holds for some $z \in \tilde{\N}$, then $x+s(z) = y+s(z)$ implies $s(x+z) = s(y+z)$. But $s$ is an inductive function, so $x +z = y+z$ which implies $x = y$ by the induction hypothesis, and by mathematical induction we have our result.
\end{proof}

\begin{proposition}\label{prop:1.1.12}
    If $x \cdot z = y \cdot z$ and $z \neq 0$, then $x =y$.
\end{proposition}
\begin{proof}
    Suppose $x,y,z \in \tilde{\N}$ such that $x\cdot z = y\cdot z$. We argue by contrapositive and suppose $x \neq y$. Then by Trichotomy (to be shown) $x < y$ or $y < x$. Without loss of generality suppose $x < y$. Then $y = x+u$ for some $u \in \N$. Then $y\cdot z = x\cdot z + u\cdot z$, and so $u\cdot z = 0$ by the cancellation property. If $z \neq 0$, $z = s(w), w \in \tilde{\N}$, so $0 = u\cdot z = u\cdot w + u$. As $u \in \N$ this implies $u\cdot w < 0$, but $0 \leq k$ for all $k \in \tilde{\N}$ which contradicts trichotomy.
\end{proof}

As noted in the previous proof we used properties of the standard order relation on the naturals which we shall now define and prove.

\begin{definition}
    If $x,y \in \tilde{\N}$ we say \begin{enumerate}
        \item $x < y$ if $y = x+u$ for some $u \in \N$
        \item $x \leq y$ if $y = x+v$ for some $v \in \tilde{\N}$
    \end{enumerate}
\end{definition}

We could also say $x \leq y$ if and only if $y \in Rx = \{x+v:v \in \tilde{\N}\}$.  We define $y > x \iff x < y$ and $y \geq x \iff x \leq y$ for all $x,y \in \tilde{\N}$.

\begin{proposition}\label{prop:1.1.13}
    For $x,y \in \tilde{\N}$, if $x \leq y$ and $y \leq x$, then $x =y$.
\end{proposition}
\begin{proof}
    As $y = x+v, v \in \tilde{\N}$, and $x = y+u$ for $u \in \tilde{\N}$ by definition, $x = x+v+u$, so by the cancellation property $v + u = 0$. Towards a contradiction suppose $v$ or $u$ is not $0$. Without loss of generality suppose $v \neq 0$, so $v \in \N$ and there exists $m \in \tilde{\N}$ such that $v = s(m)$. Then $0 = u+s(m) = s(u+m) \in \N$, which contradicts our axiom that $0 \notin \N$. Thus, $v = u = 0$, so $x = y$.
\end{proof}

\begin{proposition}[Trichotomy]\label{prop:1.1.14}
    If $x,y \in \tilde{\N}$, then one and only one of the following hold: $$x < y \text{ or } x = y \text{ or } x > y$$
\end{proposition}
\begin{proof}
    Let $x,y \in \tilde{\N}$. If $x < y$ then $y = x+u$ for some $u \in \N$. If $x =y$ then $u = 0$, but $u \in \N$ so $u \neq 0$, and $x \neq y$. If $x > y$ then $x = y+v,$ $v \in \N$, but by the proof of Proposition \ref{prop:1.1.13} this implies $u=v=0$ contradicting the fact $u,v \in \N$. By similar arguments $x =y \implies x \cancel{<} y, x \cancel{>} y$, and $x > y$ follows from the first case. Let $y \in \tilde{\N}$ and proceed by induction on $x \in \tilde{\N}$. If $x = 0$, $y = y+0$ so $y \geq x$. If $y = 0$, $x = y$, and if $y \neq 0$, $y \in \N$ so $y > x$. Suppose the claim holds for some $x \in \tilde{\N}$. If $x < y$, then $s(x) \leq y$. Then either $s(x) = y$ or $s(x) + u = y$ for some $u \neq 0$, so $u \in \N$ and $s(x) < y$. If $x = y$, $s(x) = x+1 = y+1$, so $y < s(x)$. A similar argument holds if $y < x$, since $y < s(x)$, completing the induction.
\end{proof}

We now define the partial function of subtraction on $\tilde{\N}$:

\begin{definition}
    If $x,y \in \tilde{\N}$ with $x \leq y$, then we define $z := y-x \iff y = x+z$, where $z \in \tilde{\N}$.
\end{definition}
Notice $y-x$ is well defined by the cancellation property of addition.

\begin{proposition}\label{prop:1.1.17}
    If $x,y,u \in \tilde{\N}$, with $x \leq y$, then $(y-x)u = yu-xu$.
\end{proposition}
\begin{proof}
    Let $x,y \in \tilde{\N}$ with $x \leq y$ and let $u \in \tilde{\N}$. Then there exists $w \in \tilde{\N}$ such that $y = x+w$, so $yu = xu+wu$ by distributivity, Then by definition $yu - xy = wu = (y-x)u$.
\end{proof}

Next we move on to a central property of the natural numbers which is equivalent to the axiom of mathematical induction:

\begin{theorem}[Well-Ordering Property of $\tilde{\N}$]\label{namthm:wellOrder}\index{Well-Ordering Property}
    If $T \subseteq \tilde{\N}$ is non-empty, then $T$ has a smallest element.
\end{theorem}
\begin{proof}
    We proceed by contrapositive. Suppose $T \subseteq \tilde{\N}$ and $T$ has no smallest element. Then $0 \notin T$, since for all $x \in \tilde{\N}$, $0 \leq x$, as either $x = 0$ or $x \in \N$ so $x = x+0$ and $x > 0$. Let $S = \{x \in \tilde{\N}:x < y,\forall y \in T\}$, so $0 \in S$. Inductively suppose $x \in S$. If $s(x) \in S$, we're done, so suppose $s(x) \geq y$ for some $y \in T$. But $x < y$, so $y = x+s(w)$, for some $w \in \tilde{\N}$, and $y = s(x)+w$. Thus $s(x) \leq y$, so by Proposition \ref{prop:1.1.13}, $s(x) = y \in T$. But $s(x) \leq t$ for all $t \in T$, so $s(x)$ is a minimal element of $T$, contradicting the hypothesis. Thus $s(x) \in S$, so by mathematical induction $S = \tilde{\N}$. Then as $T \subseteq \tilde{\N}\backslash S$, $T = \emptyset$ as desired.
\end{proof}

In the next section we perform an arithmetic closure of the naturals to obtain the rational field, $\Q$.


\section{Construction of The Rational Field}

First we need the notion of an equivalence relation for our constructions:

\begin{definition}[Equivalence Relation]\index{Equivalence relation}
    An equivalence relation on a set $S$ is a subset $E \subseteq S\times S$ such that \begin{enumerate}
        \item For all $x \in S$, $xEx$ (reflexivity) 
        \item For all $x,y \in S$, if $xEy$ then $yEx$ (symmetry) 
        \item For all $x,y,z \in S$, if $xEy$ and $yEz$, then $xEz$ (transitivity)
    \end{enumerate}
\end{definition}

An important property of equivalence relations is there relation to partitions of a set: in particular, we have a bijection between partitions of a set and equivalence relations.

\begin{definition}\Alsoindex{Equivalence relation}{Equivalence class}
    For an equivalence relation $\sim$ on a set $S$, and $x \in S$, the \Emph{equivalence class} for $x$ is defined by \begin{equation*}
        [x]_{\sim} := \{y \in S: x \sim y\}
    \end{equation*}
\end{definition}

Note that $[y]_{\sim} = [x]_{\sim}$ if and only if $x \sim y$. Further, the equivalence classes for $\sim $ form a partition on $S$. That is $S = \cup_{x \in S}[x]_{\sim}$, and if $[y]_{\sim} \neq [x]_{\sim},$ $[y]_{\sim}\cap[x]_{\sim} = \emptyset$.

\begin{definition}
    Define $\sim$ on $\tilde{\N}\times \tilde{\N}$ by $(a,b) \sim(x,y)$ if and only if $a+y = x+b$.
\end{definition}
We consider $(a,b)$ to be $a-b$. We note that this defines an equivalence relation, we the proof left to the reader.

\begin{definition}\index{Integers}
    We define the \Emph{Integers}, $\Z$, to be the set \begin{equation*}
        \Z := \{[(x,a)]_{\sim} \in \mathcal{P}(\tilde{\N}\times\tilde{\N}): x,a \in \tilde{\N}\} = \tilde{\N}\times\tilde{\N}/\sim
    \end{equation*}
    and we have the natural injection \begin{align*}
        \iota:\tilde{\N}&\rightarrow \Z \\
        x&\mapsto [(x,0)]
    \end{align*}
\end{definition}

We can define operations of addition and multiplication on $\Z$ inherited from $\tilde{\N}$.

\begin{definition}
    For $[(x,a)],[(y,b)] \in \Z$, we define \begin{align*}
        [(x,a)]+[(y,b)] &= [(x+y,a+b)] \\
        [(x,a)]\cdot[(y,b)] &= [(xy + ab, xb + ay)]
    \end{align*}
\end{definition}
To show these definitions are well defined we must show that the operation is independent of the choice of representative of each equivalence class. This is a routine check left to the reader.

\begin{definition}
    We define $0 = [(0,0)]$ and $-1 = [(0,1)]$ in $\Z$, and if $m = [(x,a)]$, we define $-m := [(a,x)]$.
\end{definition}

\begin{proposition}
    For all $m \in \Z$, $m \cdot (-1) = -m$.
\end{proposition}
The proof is a quick calculation: \begin{equation*}
    m\cdot (-1) = [(x,a)][(0,1)] = [(x\cdot 0+a,x+a\cdot 0)] = [(a,x)] = -m
\end{equation*}

Similarly, we have all the properties we derived for $\tilde{\N}$ for the operations on $\Z$, such as $m\cdot 0 = 0$, $m(n+k) = mn+mk$, $m+n=m+k \implies n =k$, and $m\cdot n= k\cdot n\implies m=k$ if $n \neq 0$. Now we have closed the $\tilde{\N}$ under ring operations, obtaining the integral domain $\Z$.

Next we perform a similar construction to obtain our field - this process is known as constructing a fraction field for an integral domain.

\begin{definition}
    Define an equivalence relation $\sim$ on $\Z\times \Z\backslash\{0\}$ by $(x/a)\sim(y/b)$ if and only if $xb = ya$, for $(x/a),(y/b) \in \Z\times \Z\backslash\{0\}$.
\end{definition}

It is routine to show that this is indeed an equivalence relation on the set. Next, we can define addition and multiplication operations:

\begin{definition}\index{Rationals}
    We define the rationals to be \begin{equation*}
        \Q = \Z\times \Z\backslash\{0\}/\sim
    \end{equation*}
    For $[m/n],[a/b] \in \Q$, we define $$[m/n] + [a/b] = [(mb+an)/(nb)]$$ and $$[m/n]\cdot[a/b] = [(ma)/(nb)]$$
\end{definition}

It is a routine varification that these operations are well-defined and independent of the representative. If $x = [(a/b)] \in \Q$, and $x \neq 0$ so $a \neq 0$, then we can define $$x^{-1} = \frac{1}{x} := [(b/a)] \in \Q$$ We also define $0 := [0/1], 1 := [1/1],$ and $-1 := [-1/1]$. So far we have the chain $$\tilde{\N}\hookrightarrow \Z := \tilde{\N}\times \tilde{\N}/\sim \hookrightarrow \Z\times (\Z\backslash\{0\})/\sim$$

\section{Divisibility}

We now go over some fundamental theorems of number theory involving divisibility.

\begin{definition}
    We say $x \in \N$ is \Emph{composite} if $a,b \in \N$ such that $x = ab$ and $a,b \neq 1$. If $x$ is not composite, and $x > 1$, then $x$ is said to be \Emph{prime}. That is, $x$ is prime if and only if $x = ab$ implies $a = 1$ or $b =1$.
\end{definition}

\begin{definition}\index{Divisor}
    If $x = ab$, $x,a,b \in \N$, then we say $a$ \Emph{divides} $x$, or $a$ is a \Emph{divisor} of $x$, and we write $a\;\vert\;x$.
\end{definition}

\begin{definition}
    Given $x \in \N$, define the collection of non-trivial divisors as $$D_x := \{a \in \N\backslash\{1\}:a\;\vert\;x\} \subseteq \N$$
\end{definition}

Note that if $a \;\vert\;x$, then $a \leq x$. As $D_x \subseteq \N$, and $x \in D_x$ so it is non-empty, $D_x$ has a smallest element $p_1 \in D_x$. Then $x = p_1x_1$ for some $x_1 \in \N$. Then $p_1$ is prime since if note it can be written as $p_1 = ab$ for $1 < a < p_1$, and then $a\;\vert\;x$ with $a < p_1$, contradicting its minimality. If $x_1 > 1$, then we can obtain $x_1 = p_2x_2$, for $p_2$ prime and $p_2 \geq p_1$. Repeating in this fashion, since $x$ is finite there must exist $N \in \N$ such that $x_N = 1$ and $x_{N-1} = p_N\cdot 1$. Then $x = p_1\cdot ...\cdot p_N$. This is the existence portion of the following result.

\begin{theorem}[Fundamental Theorem of Arithmetic]\index{Fundamental Theorem of Arithmetic}
    Every natural number $x > 1$ has a unique factorization, up to reordering, into a product of prime numbers.
\end{theorem}
\begin{proof}
    If $x = p_1...p_N = q_1...q_M$, then for each $1 \leq i\leq N$, $p_i\;\vert\;q_j$ for some $1 \leq j \leq M$. But, $p_i$ and $q_j$ are prime, so $p_i = q_j$, and after reordering $p_1 ...p_N = p_1...p_Nq_{N=1}...q_M$. By cancellation $q_{N+1}...q_M = 1$. Thus, $N = M$ and the terms are equal up to reordering.
\end{proof}

\begin{definition}
    We say $x,y \in \N$ are \Emph{coprime} if $x$ and $y$ have no common prime factors.
\end{definition}

\begin{proposition}
    If $x,y \in \N$ are coprime, then there exists $m,n \in \Z$ such that $$xm+ny = 1$$
\end{proposition}

\section{Reals in terms of Cauchy Sequences}

To construct the reals we use the standard notion of a completion of metric spaces using equivalence classes of Cauchy sequences. But first we must define what a sequence is, and what it means for one to be Cauchy.

\begin{definition}
    We define the \Emph{absolute value function} by $$|x| = \left\{\begin{array}{cc} x & \text{if }x \geq 0 \\ -x & \text{if } x < 0\end{array}\right.$$
\end{definition}

It is a standard proof by cases, that the absolute value function defines a norm on $\Q$.

\begin{definition}\index{Sequence}
    A sequence is a function $a:\N\rightarrow \Q$, denoted $a(j) = a_j$ and $(a_j)_{j=1}^{\infty}$.
\end{definition}

\begin{definition}\index{Convergence}
    We say a sequence $(a_j)$ converges to a number $a \in \Q$, and write $a_j\rightarrow a$, if for every $n \in \N$, there exists an index $K(n) \in \N$ such that if $j\geq K(n)$, then $|a_j - a| < \frac{1}{n}$.
\end{definition}

\begin{definition}\index{Cauchy}
    A sequence $(a_j)$ is said to be \Emph{Cauchy} if for all $n \in \N$, there exists $K(n) \in \N$ such that if $j,k \geq K(n)$, then $$|a_j - a_k| < \frac{1}{n}$$
\end{definition}

\begin{proposition}
    If $a_j\rightarrow a$, then $(a_j)$ is Cauchy.
\end{proposition}
\begin{proof}
    Since $a_j \rightarrow a$, for $n \in \N$ there exists $K(2n) \in \N$ such that if $j \geq K(2n)$, $|a_j - a| < \frac{1}{2n}$. Thus, if $k,j \geq K(2n)$, then $$|a_j - a_k| \leq |a_j - a| + |a - a_k| < \varepsilon$$ as desired.
\end{proof}

\begin{proposition}
    If $(a_j)$ is Cauchy then $(a_j)$ is bounded.
\end{proposition}
\begin{proof}
    Suppose $(a_j)$ is Cauchy. Then there exists $K(1) \in \N$ such that for $k,j\geq K(1)$, $|a_k - a_j| < 1$. Then for all $j \geq K(1)$, $|a_j| < 1 + |a_{K(1)}|$. Letting $M = \max\{|a_1|,...,|a_{K(1)-1}|, 1+|a_{K(1)}|\}$, we have that $a_n \leq M$ or all $n \in \N$, so the sequence is bounded.
\end{proof}

We now have some standard results about convergence of sequences:

\begin{proposition}\label{prop:1.5.1}
    If $a_j\rightarrow a$ and $b_j\rightarrow b$, then $$a_j+b_j\rightarrow a+b,\;\text{ and }\;a_jb_j\rightarrow ab$$ If $b \neq 0$, and $b_j \neq 0$ for all $j$, then $$a_j/b_j\rightarrow a/b$$
\end{proposition}

More generally we have 
\begin{definition}
    If $(a_j),(b_j)$ are Cauchy sequences, then $(a_j+b_j)$ is Cauchy, $(a_jb_j)$ is cauchy, and if there exists $n \in \N$ such that $|b_j| > \frac{1}{n}$ for all $j$, then $(a_j/b_j)$ is Cauchy.
\end{definition}

Although for general metric spaces we have the inclusion $$\left\{\begin{array}{cc} Convergent \\ Sequences\end{array}\right\} \subseteq \left\{\begin{array}{cc} Cauchy \\ Sequences \end{array}\right\}$$
the other inclusion is not in general true.

\begin{example}
    Let $a_j = \sum_{l=0}^j\frac{1}{l!}$, in $(\Q, d)$, $d(x,y) = |x-y|$. $a_j$ is a Cauchy sequence, as $|a_j - a_k| = \left|\sum_{l=k+1}^j\frac{1}{l!}\right| = \sum_{l=k+1}^j\frac{1}{l!}\rightarrow 0$. For $l\geq 2$ we have $\frac{1/(l+1)!}{1/l!} = \frac{1}{l} \leq \frac{1}{2}$. Then $\frac{1}{(2+j)!} \leq \frac{1}{2^j}\frac{1}{2}$. Then for $j > k \geq 2$, $$\sum_{l=k+1}^j\frac{1}{l!} = \sum_{l=k-2}^{j-2}\frac{1}{(l+2)!} \leq \sum_{l=k-2}^{l-2}\frac{1}{2^l}\frac{1}{2} < \frac{1}{2}\frac{1}{1-1/2} = 1$$ Thus, $a_j$ is a bounded increasing sequence and hence Cauchy. Now observe \begin{align*}
        a_{n+j}-a_n &= \frac{1}{(n+1)!} + ... + \frac{1}{(n+j)!} \\
        &\leq \frac{1}{n!}\left(\frac{1}{n+1}+ \frac{1}{(n+1)^2} + ... + \frac{1}{(n+1)^j}\right) \\
        &< \frac{1}{n!}\sum_{k=0}^{j-1}\frac{1}{(n+1)^{k+1}} \\
        &= \frac{1}{(n+1)!}\frac{1-\frac{1}{(n+1)^{j-1}}}{1-\frac{1}{n+1}} < \frac{1}{n!n}
    \end{align*}
    So if we fix $N \in \N$, $N+j > N+k \geq N$, then $a_{N+j} - a_{N+k} < \frac{1}{N!N} < \frac{1}{N}$. Hence $a_j$ is Cauchy. Since it is Cauchy, in the complete metric space $\R$ it is convergent, so let $a = \lim a_j$, so we observe $a = \sum_{l=0}^{\infty}\frac{1}{l!} = e$. But $e \notin \Q$, so this limit cannot be in the rationals and hence the rationals is not complete. 
\end{example}

The following is a very important series known as the \Emph{geometric series}:

\begin{proposition}
    If $a \in \Q$, with $|a| < 1$, then $\sum_{j=0}^{\infty}a^j = \frac{1}{1-a}$.
\end{proposition}

\begin{proposition}
    If $|a| < 1$, then $|a|^n\rightarrow 0$.
\end{proposition}
\begin{proof}
    If $a = 0$, then $|a|^n = 0$ for all $n$, so the result holds. Hence, suppose $a \neq 0$. Then $|a|^{j+1} < |a|^j$, so $|a|^n$ is a bounded decreasing sequence, and hence converges in $\R$. Hence $\lim\limits_{n\rightarrow \infty}|a|^n = k$ for some $k \in \R$. Then $k = \lim\limits_{n\rightarrow \infty}|a|^n = \lim\limits_{n\rightarrow \infty}|a|^{n+1} = |a|k$. But $|a| \neq 1$, so $k = 0$. Thus, $|a|^n\rightarrow 0$, as desired.
\end{proof}


\begin{proposition}[Bolzano-Weierstrass (Cauchy)]\index{Bolzano-Weierstrass}
    If $(a_j)$ is a bounded sequence, then there exists a Cauchy subsequence.
\end{proposition}
\begin{proof}
    Since $(a_j)$ is bounded, there exists $M > 0$ such that $|a_j| \leq M$ for all $j$. In particular, $a_j \in I_0 = [-M,M]$ for all $j$. Then either $[-M,0]$ or $[0,M]$ contains an infinite number of $a_j$. Let $I_1$ be the one with such. Inductively, suppose there exists $k \in \tilde{\N}$ such that an infinite number of $a_j$ are in $I_k$, for all $0 \leq l \leq k-1$ $I_{l+1}\subseteq I_l$, and $\ell(I_l) = \frac{2M}{2^l}$. Then, we have a sequence $I_j$ of closed intervals containing infinitely many terms of $a_j$. Let $b_1 = a_1$, and let $b_k = a_{j(k)}$, where $j(k) = \min\left\{m \in \N: a_m \in I_k, m > j(k-1)\right\}$, which exists and is well defined by the construction of $I_k$ and the well-ordering of $\N$. Then $b_k = a_j(k)$ is a subsequence of $j$, as $j(k) < j(k+1)$ for all $k$. Now, fix $n \in \N$. As $2^{-j}\rightarrow 0$, there exists $K(2Mn) \in \N$ such that for $j \geq K(2Mn)$, $\frac{1}{2^j} < \frac{1}{2Mn}$. Then, for $k,l \geq K(2Mn)$, $b_k,b_l \in I_{K(2Mn)}$, so $$|b_k - b_l| \leq \ell(I_{K(2Mn)}) = \frac{2M}{2^{K(2Mn)}} < \frac{2M}{2Mn} = \frac{1}{n}$$ Thus $b_j$ is Cauchy.
\end{proof}

\begin{corollary}
    Each bounded Monotone sequence is Cauchy.
\end{corollary}
\begin{proof}
    Let $(a_j)$ be a bounded monotone sequence. Then we have a Cauchy subsequence $(a_{j_n})$. Fix $n \in \N$. Then there exists $K(n) \in \N$ such that if $k,l \geq K(n)$, $|a_{j_k} - a_{j_l}| < \frac{1}{n}$. Let $K'(n) = j_{K(n)}$. Then for $k,l \geq K'(n)$, let $m \in \N$ such that $j_m \geq k,l$ and $m \geq K(n)$. Then as $a_j$ is an increasing (decreasing) sequence, so $$a_{j_{K(n)}} \leq a_k \leq a_l \leq a_{j_m}\;(\text{respectively }a_{j_{K(n)}} \geq a_k \geq a_l \geq a_{j_m})$$ Then $0 \leq a_l - a_k \leq a_{j_m} - a_{j_{K(n)}}$, so $|a_l - a_k| < \frac{1}{n}$, and similarly for a decreasing sequence. Hence $a_j$ is Cauchy.
\end{proof}

We now begine defining the reals using equivalence relations on our Cauchy sequences:

\begin{definition}
    Let $\mathcal{S} = \{(a_j) \subseteq \Q:(a_j) \text{ is Cauchy}\}$. Define an equivalence relation $\sim$ on $\mathcal{S}$ by $$(a_j)\sim (b_j) \iff a_j-b_j\rightarrow 0$$
\end{definition}

It is a routine check that $\sim$ is an equivalence relation on $\mathcal{S}$. 

\begin{definition}\index{Reals}
    We define $\R := \mathcal{S}/\sim$, so $x \in \R$ if and only if $x = [(a_j)]$ for some Cauchy sequence $(a_j)$ in $\Q$.
\end{definition}

\begin{definition}
    If $x = [(a_j)], y = [(b_j)] \in \R$, we define $$x+y := [(a_j+b_j)]\;\;xy := [(a_jb_j)]$$ and $-x := [(-a_j)]$.
\end{definition}

As with the notion of an equivalence relation, it is a routine check using the boundedness of Cauchy sequences to prove that these operations are well defined. We can then define a natural injection $\Q\hookrightarrow \R$ by $a\mapsto [(a,a,a,...)]$. In particular, $0:= [(0,0,0,...)]$ in $\R$. 

Now, note that if $x = [(a_j)], y = [(b_j)] \in \R$, then $x \neq y$ if and only if $a_j-b_j$ does not converge to $0$, so there exists $n \in \N$ such that for all $j \in \N$, there exists $k \geq j$ such that $$|a_k - b_k| \geq \frac{1}{n}$$ Specializing to the case of $y = 0=[(0,0,0,...)]$, as $(a_j)$ is Cauchy, there exists $K(2n) \in \N$ such that $k,l \geq K(2n)$, $|a_k - a_l| < \frac{1}{2n}$, so in particular $|a_j| \geq |a_k| - |a_j - a_k| > \frac{1}{2n}$ for all $j \geq K(2n)$. It follows that either $a_j > \frac{1}{2n} > 0$ for all $j \geq K(2n)$, or $a_j < \frac{-1}{2n} < 0$ for all $j \geq K(2n)$.

Thus, if $x \neq 0$, then $x = [(a_j)] = [(\alpha_j)]$ such that there exists $n \in \N$ such that either $\alpha_j \geq \frac{1}{2n}$ for all $j$, or $\alpha_j \leq \frac{-1}{2n}$ for all $j$. Then we can define $x^{-1} = \frac{1}{x} := [(\alpha_j^{-1})]$.

\begin{definition}
    We define the following subsets of $\R$: \begin{align*}
        \R^+ &= \{x = [(a_j)]: \exists n,K \in \N;a_j\geq \frac{1}{2n},\forall j \geq K\} \\
        \R^- &= \{x = [(a_j)]: \exists n,K \in \N; a_j \leq \frac{-1}{2n},\forall j\geq K\}
    \end{align*}
\end{definition}
We have shown that if $x \neq 0$ then either $x \in \R^+$ or $x \in \R^-$. Thus $$\R = \R^+ \sqcup \{0\}\sqcup \R^-$$

\begin{proposition}
    For $x \in \R$, $x \in \R^+$ if and only if $-x \in \R^-$, and $x \in \R^-$ if and only if $-x \in \R^+$.
\end{proposition}

\begin{definition}
    We define a total order $<$ on $\R$ by $$x < y \iff y-x \in \R^+ \iff x = [(a_j)],y=[b_j)],\exists n,K \in \N;b_j-a_j \geq \frac{1}{2n}\forall j \geq K$$
\end{definition}

We have a few standard results about the order relation on $\R$: 

\begin{proposition}\label{prop:1.6.4}
    Let $x_1,x_2,y_1,y_2 \in \R$. Then \begin{itemize}
        \item $x_1 < y_1, x_2 < y_2 \implies x_1+x_2 < y_1 + y_2$
        \item $x_1 < y_1 \implies -y_1 < -x_1$
        \item $0 < x_1 < y_1$, $c > 0$, then $0 < cx < cy$
        \item $0 < x < y \iff 0 < \frac{1}{y} < \frac{1}{x}$
    \end{itemize}
\end{proposition}

Note that in $\N$ we have well-ordering, but under the standard orders on $\Q$ and $\R$ this property does not hold.

\begin{definition}\index{Bounds}
    For $S \subseteq \R$, we say $x$ is an \Emph{upper bound} of $S$ if $s \in S$ implies $s \leq x$. Dually, we say $y$ is a \Emph{lower bound} for $S$ is $s \in S$ implies $s \geq y$.
\end{definition}

\begin{definition}
    For $S \subseteq \R$, the \Emph{least upper bound}, denoted $\sup S$, is an upper bound for $S$ such that if $y$ is any other upper bound for $S$ then $\sup S \leq y$. Dually, the \Emph{greatest lower bound}, denoted $\inf S$, is a lower bound for $S$ such that if $y$ is any other lower bound for $S$, then $y \leq \inf S$.
\end{definition}

\begin{theorem}[Completeness of $\R$]\index{Completeness}
    If $(x_j)$ is a Cauchy sequence of real numbers, then there exists $x = [(a_j)] \in \R$ such that $x_j \rightarrow x$, of $x_j \sim a_j$, extending the equivalence relation to $\R$.
\end{theorem}


\begin{proposition}\label{prop:1.6.12}
    If $S$ is a non-empty subset of $\R$ that has an upper bound, then there exists $x \in \R$ such that $x = \sup S$.
\end{proposition}
\begin{proof}
    By hypothesis, there exists $x_0 \in \R$ such that for all $s \in S$, $s \leq x_0$. As $S$ is non-empty, there exists $s_0 \in S$. Define an interval $I_0 = [s_0,x_0]$, and divide it into $2$ subintervals, $I_0^l,I_0^r$. If $I_0^r\cap S \neq \emptyset$ let $I_1^* = I_0^r$, and otherwise let $I_1^* = I_0^l$. In either case $I_1 = [s_1,x_1]$ is such that $x_1$ is an upper bound of $S$, and where we choose $s_1 \in I_1^*$ such that $s_1 \in S$. Further, $s_0 \leq s_1 \leq x_1 \leq x_0$, and letting $x_0 - s_0 = L$, $\ell(I_1) \leq \frac{L}{2}$. Proceeding inductively we find sequences $s_0\leq s_1\leq s_2 \leq ...$ in $S$ and $x_0 \geq x_1 \geq x_2 \geq ...$, with $I_j = [s_j,x_j]$, $\ell(I_j) \leq \frac{L}{2^j}$, with $x_j \geq s$ for all $s \in S$, and all $j \in \tilde{\N}$. Note $x_j$ is a decreasing bounded sequence, so it converges to some $x \in \R$, as $\R$ is complete. As $x_j \geq s$ for all $s \in S$, $x \geq s$ so $x$ is an upper bound. Further, if $\varepsilon > 0$, there exists $K \in \N$ such that for all $j \geq K$, $\frac{1}{2^j} < \frac{\varepsilon}{L}$, so $0 \leq x_j - s_j < \frac{L}{2^j} < \varepsilon$ for all $j \geq K$. Then $x-\varepsilon < s_j$ for all $j \geq K$. Thus, $x-\varepsilon$ is not an upper bound of $S$, and hence $x$ must be the least upper bound.
\end{proof}


\section{Metric Properties of the Reals}

First we extend our definition of sequences to the reals:

\begin{definition}\index{Convergence}
    A sequence $(p_j)$ in $\R$ converges to a point $p \in \R$ if and only if for every $\varepsilon > 0$ there exists $N \in \N$ such that if $j \geq N$, then $|p_j - p| < \varepsilon$.
\end{definition}

Using sequences we can define notions of our topology, such as closed and open sets, and limit points:

\begin{definition}\index{Closed}
    $S \subseteq \R$ is said to be \Emph{closed} if and only if whenever $(p_j) \subseteq S$ is a sequence in $S$ which converges to a point $p \in \R$, then $p \in S$.
\end{definition}

\begin{definition}\index{Accumulation point}
    A point $p \in \R$ is said to be a \Emph{limit point} of $S$ if there exists $(p_j) \subseteq S$ such that $p_j$ converges to $p$, and $p_j \neq p$ for all $j \in \N$.
\end{definition}

Note that $S$ is closed if and only if $S$ contains all of its limit points.

\begin{definition}\index{Open}
    $U\subseteq \R$ is said to be \Emph{open} if and only if $U^c = \R\backslash U$ is closed.
\end{definition}

\begin{definition}\index{Closure}
    For $S \subseteq \R$, the \Emph{closure} of $S$, $\overline{S}$, is defined as $$\overline{S}:= S \cup S'$$ where $$S' = \{p \in \R: p \text{ is a limit point of } S\}$$
\end{definition}

\begin{proposition}
    For all $S \subseteq \R$, $\overline{\overline{S}} = \overline{S}$
\end{proposition}
\begin{proof}
    Let $(p_j) \subseteq \overline{S}$ which converges to some point $p \in \R$. Then for each $j$ we have $(b_{jk})$ in $S$ which converges to $p_j$. For each $j \in \N$, there exists $K(j) \in \N$ such that for $k \geq K(j)$, $|b_{jk} - p| < \frac{1}{j}$. Define $(c_j)$ by $c_j = b_{jK(j)}$. Fix $\varepsilon > 0$. Then there exists $N \in \N$ such that $j \geq N$ implies $|p_j - p| < \frac{\varepsilon}{2}$. By the Archimedian property there exists $n \in \N$ such that $\frac{1}{n} < \frac{\varepsilon}{2}$. Then for a $j \geq \max\{n,N\}$, \begin{align*}
        |c_j - p| \leq |c_j - p_j| + |p_j - p| < \frac{1}{n} + \frac{\varepsilon}{2} < \varepsilon
    \end{align*}
    Thus $(c_j) \subseteq S$ and $c_j\rightarrow p$, so $p \in \overline{S}$. Hence, $\overline{S}\supseteq \overline{\overline{S}}$, and by definition $\overline{S} \subseteq \overline{\overline{S}}$, so $\overline{S} = \overline{\overline{S}}$.
\end{proof}

\begin{theorem}\label{thm:1.9.1}
    Every Cauchy sequence in $\R$ has a limit point in $\R$.
\end{theorem}

Note if $(x_j) = ([(a_{jk})])$ is Cauchy in $\R$, then $(a_{jj})$ is Cauchy in $\Q$ with $a_{jj} - x_j \rightarrow 0$, so then $x_j$ converges to $[(a_{jj})]$.

\begin{proposition}[Density of the Rationals]
    For all $x \in \R$ and $\varepsilon > 0$, there exists $y \in \Q$ such that $|y-x| < \varepsilon$.
\end{proposition}
In particular, for all $a < b$ in $\R$, there exists $c \in \Q$ such that $a < c < b$. Indeed, for $x = [(a_j)]$, $a_j \rightarrow x$ so there exists $N \in \N$ such that $|a_N - x| < \varepsilon$ for any $\varepsilon > 0$.

\begin{definition}
    A subset $K \subseteq \R$ is \Emph{sequentially compact} if and only if for every \Emph{infinite sequence} $(p_j) \subseteq K$, there exists a subsequence which converges to a point in $K$.
\end{definition}

\begin{theorem}[Bolzano-Weierstrass Property]\index{Bolzano-Weierstrass}
    Every bounded sequence of real numbers has a convergent subsequence.
\end{theorem}


\begin{theorem}\label{thm:1.9.2}
    If $K \neq \emptyset$, $K \subseteq \R$, and $K$ is closed and bounded, then $K$ is sequentially compact.
\end{theorem}
\begin{proof}
    If $K \subseteq \R$, $K \neq \emptyset,$ is bounded and $(p_j) \subseteq K$, $(p_j)$ has a convergent subsequence $(p_{j_k})$ by Bolzano-Weierstrass, so $p_{j_k}\rightarrow p$ for some $p \in \R$. But $K$ is closed so $(p_{j_k}) \subseteq K$, so $p \in K$.
\end{proof}

Note that if $K \subseteq \R$ is compact, then $K$ is closed since all subsequences of a convergent sequence converge to the same point. Additionally, $K$ is bounded as otherwise we can construct $p_1 \in K$, $p_2 \in K$ such that $|p_2| > |p_1| + 1$, and for $p_k \in K$, choose $p_{k+1} \in K$ such that $|p_{k+1}| > |p_k| + 1$. Thus, for all $j,k \in \N$, $|p_j - p_k| > 1$, so $(p_j)$ has no convergent subsequence.

\begin{theorem}[Heine-Borel]\index{Heine-Borel}
    If $K \neq \emptyset, K \subseteq \R$, the following are equivalent: \begin{itemize}
        \item $K$ is sequentially compact
        \item $K$ is closed and bounded
    \end{itemize}
\end{theorem}

If $K$ is compact, $K \neq \emptyset$, in $\R$, then there exists $a,b \in K$ such that $$a = \min K := \inf K\;\text{ and }\;b = \max K := \sup K$$ which is to say $K$ contains its infimum and supremum.

\begin{definition}\index{Continuity}
    A function $f:S\rightarrow \R$, $\emptyset \neq S \subseteq \R$, is said to be \Emph{continuous} at a point $p \in S$ if whenever $(p_j) \subseteq S$ such that $p_j\rightarrow p$, then $f(p_j)\rightarrow f(p)$
\end{definition}

\begin{definition}\index{Isolated Point}
    A point $p \in S$ is said to be an \Emph{isolated point} of $S$ if there exists some $\varepsilon > 0$ such that $(p-\varepsilon,p+\varepsilon) \cap S = \{p\}$
\end{definition}
Every function is continuous at isolated points of its domain.

\begin{definition}
    If $f:S\rightarrow \R$ is continuous at every point $p \in S$, we say $f$ is \Emph{continuous} on $S$.
\end{definition}

\begin{proposition}\label{prop:1.9.4}
    If $K \subseteq \R$, $K \neq \emptyset$, is a compact subset of $\R$, and $f:K\rightarrow \R$ is continuous, then $f(K)$ is compact.
\end{proposition}
\begin{proof}
    Let $(q_k) \subseteq f(K)$. Then we have $(p_k) \subseteq K$ such that $f(p_k) = q_k$ for all $k$. Then as $K$ is sequentially compact there exists $p \in K$ and a subsequence $(p_{k_j}) \subseteq K$ such that $p_{k_j}\rightarrow p$. As $f$ is continuous we have $q_{k_j} = f(p_{k_j}) \rightarrow f(p)$, where $f(p) \in f(K)$. Thus $f(K)$ is sequentially compact as claimed.
\end{proof}

\begin{proposition}\label{prop:1.9.5}
    If $\emptyset \neq K \subseteq \R$ is sequentially compact and $f:K\rightarrow \R$ is continuous on $K$, then there exist $q,p \in K$ such that $$f(p) = \max_{K}f,\;\;f(q) = \min_Kf$$
\end{proposition}

\begin{theorem}[Intermediate Value Theorem]\index{IVT}
    If $f:[a,b]\rightarrow \R$ is continuous on $[a,b]$ and $f(a) < c < f(b)$ (or $f(a) > c > f(b)$), then there exists $x \in (a,b)$ such that $f(x) = c$.
\end{theorem}
\begin{proof}
    Let $S = \{y \in [a,b]: f(y) \leq c\}$. Without loss of generality suppose $f(a) < c < f(b)$ (if the other inequality holds, replace $f$ with $-f$). THen $a \in S$ and $b \notin S$. Further, if $(y_j) \in S$, $y_j\rightarrow y$, then by continuity $f(y_j)\rightarrow f(y)$ and as $f(y_j) \leq c$ for all $j$, $f(y) \leq c$. Thus $y \in S$, so $S$ is closed. As $S \subseteq [a,b]$, $S$ is bounded, so by Heine-Borel $S$ is compact. Let $x = \max S \in S$. Then $f(x) \leq c$. If $f(x) < c$, then for some $\varepsilon > 0$, $f(y) < c$ for all $y \in (x-\varepsilon,x+\varepsilon)$. Let $\varepsilon = c-f(x) > 0$. As $f$ is continuous, there exists $\delta > 0$ such that if $|x-y| < \delta$, $|f(x) - f(y)| < \frac{\varepsilon}{2}$. Then $c-f(y) = c-f(x) - (f(y) - f(x)) \geq |c-f(x)| - |f(y) - f(x)|$, which is greater than or equal to $\varepsilon/2$, so $f(y) < c$. Taking $y = x+\frac{\delta}{2}$, $f(y) \leq c$, so $y \in S$, but $y > x = \max S$ which is a contradiction. Thus, $f(x) \cancel{<} c$, so $f(x) = c$.
\end{proof}

\begin{proposition}\label{prop:1.9.7}
    Suppose $K$ is sequentially compact and $X_1 \supseteq X_2 \supseteq X_3 \supseteq ...$ is a sequence of closed subsets of $K$ so all $X_i$ are compact by Heine-Borel. If $X_m \neq \emptyset$, for all $m$, then $\bigcap_{m\geq 1}X_m\neq \emptyset$.
\end{proposition}
\begin{proof}
    Let $x_m \in X_m$. As $K$ is compact and $x_m \in K$, there exists a convergent subsequence $x_{m_j}\rightarrow x \in K$. Since $X_1 \supseteq X_2 \supseteq ...$, $$\{x_{m_l}: l\geq j\}\subseteq X_{m_j}$$ But $X_{m_j}$ is closed, so $x \in X_{m_j}$, for all $j$. Then for all $m \in \N$, $x \in X_m$ as for all $n \in \N$ there exists $m_j \geq n$ so $x \in X_{m_j} \subseteq X_n$. Thus $x \in \bigcap_{m\geq 1}X_m$,a s claimed.
\end{proof}

\begin{corollary}\label{cor:1.9.8}
    If $K$ is sequentially compact and $U_1 \subseteq U_2 \subseteq ...$ is a sequence of open sets such that $K \subseteq \bigcup_{j\geq 1}U_j$, then there exists $M \in \N$ such that $K \subseteq U_M$.
\end{corollary}
Use Proposition \ref{prop:1.9.7} with $X_j = K \backslash U_j$.

We now discuss some general results on open and closed sets: 

\begin{proposition}
    If $\{A_{\alpha}\}_{\alpha \in J}$ is a family of closed sets in $\R$, then $\bigcap_{\alpha\in J}A_{\alpha}$ is closed. If $A$ and $B$ are closed, then $A \cup B$ is closed.
\end{proposition}
\begin{proof}
    Suppose $A_{\alpha},\alpha \in J$ are as in the hypothesis. If $\emptyset = \bigcap_{\alpha \in J}A_{\alpha}$ then the claim vauously holds. Otherwise, let $(p_j) \subseteq \bigcap_{\alpha \in J}A_{\alpha}$ such that $p_j \rightarrow p \in \R$. As $A_{\alpha}$ is closed for all $\alpha \in J$, it follows that $p \in A_{\alpha}$, so $p \in \bigcap_{\alpha \in J}A_{\alpha}$. 

    Next, let $A$ and $B$ be closed, and take $(p_j) \subseteq A\cup B$ such that $p_j\rightarrow p \in \R$. Either infinitely many points of the sequence are in $A$ or infinitely many are in $B$. Without loss of generality suppose infinitely many are in $A$. Then there exists a subsequence $(p_{j_k}) \subseteq (p_j)$ contained in $A$, which will converge to $p$ so as $A$ is closed $p \in A$. Thus $p \in A \cup B$, so the union is closed.
\end{proof}

\begin{corollary}
    If $\{U_{\alpha}\}_{\alpha \in J}$ is a family of open sets in $\R$, then $\bigcup_{\alpha\in J}U_{\alpha}$ is open. If $A$ and $B$ are open, then $A \cap B$ is open.
\end{corollary}

Conversely, we have $I_n = [-1+\frac{1}{n},1-\frac{1}{n}]$, a collection of closed intervals, who's union is $\bigcup_{n\geq 1}I_n = (-1,1)$ is not closed. Further, if $U_n = (-\frac{1}{n},1+\frac{1}{n})$, then $\bigcap_{n\geq 1}U_n = [0,1]$ is not open.

\begin{definition}\index{Balls}
    The ball of radius $r > 0$ centered at $x \in \R$ is defined by $$B_r(x) := \{y \in \R:|x-y| < r\}$$ 
\end{definition}

\begin{proposition}
    $U \subseteq \R$ is open if and only if for all $x \in U$, there exists $r_x > 0$ such that $B_{r_x}(x) \subseteq U$.
\end{proposition}
\begin{proof}
    First we prove the reverse implication: \begin{itemize}
        \item[$\impliedby$] If for all $x \in U$ there exists $r_x > 0$ such that $B_{r_x}(x) \subseteq U$, then $U = \bigcup_{x \in U}B_{r_x}(x)$. Each $B_{r_x}(x) = (x-r_x,x+r_x)$ is open as $(-\infty,x-r_x]\cup[x+r_x,\infty)$ is a finite union of closed sets. Thus $U$ is open, being the union of open sets.
        \item[$\implies$] Towards a contradiction there exists $x \in U$ such that for all $r > 0$, $B_r(x) \cap U^c \neq \emptyset$. Then by the axiom of choice there exists $f:X\rightarrow \bigcup X$ with $X = \{B_{1/n}(x)\cap U^c:n \in \N\}$, and we can define a sequence $a(n) = f(B_{1/n}(x)\cap U^c)$ which converges to $x$, and $(a_n) \subseteq U^c$ which is closed. But $x \in U$ implies $x \notin U^c$ contradicting the closedness of $U^c$, so $U$ must satisfy the hypothesis.
    \end{itemize}
\end{proof}

We mention some relevant and important topological properties which $\R$ satisfies, but we leave the definition of a topology to later on.

\begin{definition}\index{Separable}
    A topological space $(X,\tau)$ is called \Emph{separable} if it has a \Emph{countable dense subset}.
\end{definition}

$\R$ is an example of a separable space, with countable dense subset $\Q$.

\begin{definition}\index{Lindel\"{o}f}
    A topological space $(X,\tau)$ is called \Emph{Lindel\"{o}f} if and only if every open cover of $X$ has a countable subcover.
\end{definition}

\begin{definition}\index{Second countable}
    A topological space $(X,\tau)$ is called \Emph{second countable} if $\tau$ has a countable base.
\end{definition}

All metrizable spaces are second countable if and only if they are separable, as we can take the rational balls around points of the countably dense subset. THus, $\tau_{\R} = \bigcup \mathcal{B}$, where $\mathcal{B} = \{B_p(q):p,q \in \Q, p > 0\}$ is a countable base.

\begin{definition}\index{Covering}
    A \Emph{covering} of a set $F$ is any family of sets $\{X_{\alpha}\}_{\alpha \in \mathcal{A}}$, such that $F \subseteq \bigcup_{\alpha \in \mathcal{A}} X_{\alpha}$.
\end{definition}

\begin{definition}\Alsoindex{Covering}{Open covering}
    An \Emph{open covering} of a topological space is a covering by open sets.
\end{definition}

\begin{proposition}\label{prop:1.9.11}
    If $K \subseteq \R$ is sequentially compact, then every open covering of $K$ has a finite subcovering.
\end{proposition}
\begin{proof}
    Suppose $\emptyset\neq K \subseteq \R$ is sequentially compact. Let $K \subseteq \bigcup_{\alpha \in J}U_{\alpha}$ be an open covering. Note $U_{\alpha} = \bigcup_{x \in U_{\alpha}}B_{p_{\alpha,x}}(q_{\alpha,x})$ such that $x \in B_{p_{\alpha,x}}(q_{\alpha,x})$, as $U_{\alpha}$ is open. Hence $$K \subseteq \bigcup_{\alpha \in J}U_{\alpha} = \bigcup_{\alpha \in J}\bigcup_{x \in U_{\alpha}}B_{p_{\alpha,x}}(q_{\alpha,x})$$ but the right side consists of countably many distinct open sets. Now consider $K \subseteq \bigcup_{j\geq 1}V_j$ is countable. Let $J_n = \bigcup_{j=1}^nV_j$. Then $K \subseteq \bigcup_{j\geq 1}J_j$, and $J_1 \subseteq J_2 \subseteq ...$ so by Proposition \ref{prop:1.9.8} there exists $M \in \N$ such that $K \subseteq J_M = \bigcup_{j=1}^MV_j$. Thus, in particular there exist $B_{p_{\alpha,x_1}}(q_{\alpha,x_1}),...,B_{p_{\alpha,x_M}}(q_{\alpha,x_M})$ such that $K \subseteq \bigcup_{j=1}^MB_{p_{\alpha,x_j}}(q_{\alpha,x_j})$. Thus $K \subseteq \bigcup_{j=1}^MU_{\alpha_j}$, so we have a finite subcovering of $K$ as desired.
\end{proof}

\begin{proposition}
    If $K \subseteq \R$ is topologically compact, then $K$ is sequentially compact.
\end{proposition}
\begin{proof}
    We prove the equivalent notion of limit point compactness (which is equivalent for metric spaces). Then we argue by contrapostive, supposing $S$ has no accumulation points. Then $S$ and $S_x = S\backslash\{x\}$ is closed for all $x \in S$. Setting $U_x = \R\backslash S_x$, we have that $K = \left(\bigcup_{x \in S}U_x\right)\cup \R\backslash S$ is an open cover, and as $K$ is topologically compact we have a finite subcover $U_{x_1},...,U_{x_N},\R\backslash S$. Then $U_{x_1},...,U_{x_N}$ covers $S$, so $S = \bigcup_{i=1}^NU_{x_i}\cap S = \bigcup_{i=1}^N\{x_i\} = \{x_1,...,x_N\}$, so $S$ is finite. Thus, $K$ is limit point compact as desired.
\end{proof}

Thus, we have the equivalence between sequentially compact, topologically compact, and limit point compact, for subsets of $\R$.




%
\section*{Appendix: Cardinality}
%
\addcontentsline{toc}{section}{Appendix: Cardinality}

In this appendix we investigate the notion of the size of a set. First, we define the set $$I_n := \{j \in \N:j \leq n$$ the prototypical set of size $n$.

\begin{lemma}
    $I_1 = \{1\}$, and $I_{n+1} = I_n \cup \{n+1\}$.
\end{lemma}
\begin{proof}
    If $n  =1$, $I_1 = \{j \in \N: j \leq 1\} = \{1\}$, so the base case holds. Further, $I_2 = \{j \in \N:j \leq 2\} = \{1,2\} = I_1 \cup\{2\}$. Now, suppose for some $j \in \N$, $I_{j+1} = I_j \cup\{j+1\}$. Then $$I_{j+2} = \{k \in \N:k\leq j+2\} = \{k \in \N:k\leq j+1\lor k = j+2\} = I_{j+1}\cup \{j+2\}$$
\end{proof}

\begin{definition}
    A non-empty set $S$ has $n$ elements if and only if there exists a bijective map $\varphi:S\rightarrow I_n$.
\end{definition}

\begin{proposition}\label{prop:1.8.2}
    For $m,n \in \N$, if there exists an injection $\varphi:I_m\rightarrow I_n$, then $m \leq n$.
\end{proposition}
\begin{proof}
    If $n = 1$, then $I_n = I_1 = \{1\}$. Now, suppose $\varphi:I_m\rightarrow I_1$ is an injection. If $x,y \in I_m$, then $\varphi(x) = 1 = \varphi(y)$, so by injectivity $x = y$. Thus, $I_m$ has only one element, and since $1 \in I_m$, we must have $I_m = \{1\} = I_1$. Hence, $m = 1 \leq 1 = n$. Assume the result is true for some $1 \leq n < N$. Then let $\varphi:I_m\rightarrow I_N$ be an injection. If $m = 1$ the result is immediately satisfied, so suppose $m \geq 2$. 
    \begin{itemize}
        \item[(1)] Suppose there exist $j \in I_m$ such that $\varphi(j) = N$. Then define $\psi:I_{m-1}\rightarrow I_{N-1}$ by $\psi(l) = \varphi(l)$ for $l < j$, and $\psi(l) = \varphi(l+1)$ for $j \leq l \leq m-1$. Then $\psi$ is injective because $\varphi$ is injective, so the the induction hypothesis $m-1 \leq N-1$, so $m \leq N$.
        \item[(2)] If there does not exist $j \in I_m$ such that $\varphi(j) = N$, then we can restrict the codomain of $\varphi$ to obtain $\varphi:I_m\rightarrow I_{N-1}$. By the induction hypothesis $m \leq N-1 < N$, as desired.
    \end{itemize}
\end{proof}

\begin{corollary}\label{cor:1.8.3}
    If there exists $\varphi:I_m\rightarrow I_n$ bijective, then $m = n$.
\end{corollary}

\begin{corollary}\label{cor:1.8.4}
    Suppose $S$ is a set, $n,m \in \N$, and there exist bijections $\varphi:S\rightarrow I_n$ and $\psi:S\rightarrow I_m$, then $n = m$.
\end{corollary}

The result follows from considering $\varphi\circ \psi^{-1}:I_m\rightarrow I_n$.

\begin{definition}
    If either $S = \emptyset$ or $S$ has $n$ elements for some $n \in \N$, then we say $S$ is \Emph{finite}. Otherwise, $S$ is said to be \Emph{infinite}.
\end{definition}

\begin{proposition}\label{prop:1.8.5}
    If $n \in \N$ and $S \subseteq I_n$, then there exists $m \leq n$ and $\varphi:S\rightarrow I_m$ bijective.
\end{proposition}
\begin{proof}
    If $n = 1$, then $I_1 = \{1\}$ and the only non-empty subset is $S = \{1\} = I_1$ itself. Then $\varphi:S\rightarrow I_1$ given by $\varphi(1) = 1$ is a bijection so the base case holds. Suppose for $k \geq 1$, if $S \subseteq I_k$, then there exists $m \leq k$ such that $\varphi_k:S\rightarrow I_m$, bijective. Suppose $S \subseteq I_{k+1}$. If $S = I_{k+1}$, then $\text{id}:I_{k+1}\rightarrow I_{k+1}$ is the desired bijection. Otherwise, there exists $j \in I_{k+1}$ such that $j \notin S$. If $j = k+1$, define $\varphi:S\rightarrow I_k$ by $\varphi(s) = s$ for all $s \in S$. Then $\varphi$ is an injection and $\varphi(S) \subseteq I_k$ so by the induction hypothesis there exists $m \leq k$ and a bijection $\psi:\varphi(S)\rightarrow I_m$. Then $\psi\circ \varphi:S\rightarrow I_m$ is bijective. If $j \neq k+1$, then define $\varphi(S)\rightarrow I_k$ by $\varphi(l) = l$ for $l \leq k$, and $\varphi(k+1) = j$. Then $\varphi$ is injective, and by the induction hypothesis there exists $m \leq k$ and a bijection $\psi:\varphi(S)\rightarrow I_m$, so $\psi\circ\varphi:S\rightarrow I_m$ is the desired bijection.
\end{proof}

\begin{proposition}\label{prop:1.8.6}
    $\N$ is not finite.
\end{proposition}
\begin{proof}
    If $\N$ was finite then there would exist $n \in \N$ and a bijection $\varphi:I_n\rightarrow \N$. As $I_{n+1} \subseteq \N$, if we restrict $\varphi$ to $\varphi^{-1}(I_{n+1}) = S$, we have $\psi:S\rightarrow I_{n+1}$, which is bijective. But $S\subseteq I_n$, so by Proposition \ref{prop:1.8.5} $S$ has $m$ elements with $m \leq n$, and as $n+1 = m \leq n$, a contradiction. Thus, $\N$ must be infinite.
\end{proof}

\begin{proposition}\label{prop:1.8.7}
    If $S$ is not finite, then there exists an injection $\varphi:\N\rightarrow S$.
\end{proposition}
\begin{proof}
    As $S$ is non-empty, there exists $s_1 \in S$, so define $\varphi_1(1) = s_1$. Suppose there exists $k \in \N$ such that for $\varphi_k(l) = s_l \in S\backslash\{s_1,...,s_{l-1}$ for all $1 \leq l \leq k$. Then as $S$ is infinite, there exists $s_{k+1} \in S$ with $s_{k+1} \notin \{s_1,...,s_k\}$, so we define $\varphi_{k+1}(k+1) = s_{k+1}$ and $\varphi_{k+1}(l) = \varphi_k(l)$ for all $1 \leq l \leq k$. Thus, for all $n \in \N$ we have $\varphi_n:I_n\rightarrow S$ injective, and for all $m \leq n$, $\varphi_n\vert_{I_m} = \varphi_m:I_m\rightarrow S$. Define $\Phi(m) = \varphi_n(m)$ for all $n \geq m$. Then $\Phi:\N\rightarrow S$ is well defined and injective.
\end{proof}

\begin{definition}\index{Countably infinite}
    We say that a set $S$ is \Emph{countably infinite} if there exists a bijection $\varphi:S\rightarrow \N$.
\end{definition}

\begin{definition}\index{Cardinality}
    Two sets $S$ and $T$ have the same cardinality if there exists a bijection between them, and we write $\text{Card}(S) = \text{Card}(T)$.
\end{definition}

\begin{definition}
    If $S$ is finite: \begin{itemize}
        \item $\text{Card}(S) = 0$ if $S = \emptyset$
        \item $\text{Card}(T) = n$ if $S$ has $n$ elements.
    \end{itemize}
\end{definition}

We now move on to a fundamental theorem on cardinalities of sets:

\begin{theorem}[Schr\"{o}der-Bernstein Theorem]\index{Schr\"{o}der-Bernstein Theorem}
    If $S$ and $T$ are two non-empty sets such that there exist injective maps $$\varphi:S\hookrightarrow T\;\text{ and }\;\psi:T\hookrightarrow S$$ then there exists a bijection $\Phi:S\rightarrow T$.
\end{theorem}
\begin{proof}
    Let $\varphi:S\rightarrow T$ and $\psi:T\rightarrow S$ be the injections in the hypothesis. If $s \in S$ such that $\varphi(s) = t$, we say $s$ is a parent of $t$. Similarly, if $t' \in T$ such that $\psi(t') = s' \in S$, then we say $t'$ is a parent of $s'$. For elements in $S$ and $T$ there are three disjoint cases: \begin{itemize}
        \item[a)] The set of elements who have an infinite number of ancestors
        \item[b)] The set of elements whose last ancestor is an element of $S$
        \item[c)] The set of elements whose last ancestor is an element of $S$
    \end{itemize}
    Define $S_a,T_a,S_b,T_b,S_c,T_c$ be the corresponding sets, so $S = S_a\sqcup S_b\sqcup S_c, T = T_a\sqcup T_b\sqcup T_c$. I claim that $\varphi\vert_{S_a}:S_a\rightarrow T_a$ is bijective. Indeed, $\varphi$ is injective. If $s \in S_a$, $\varphi(s) \in T_a$ as all ancestors of $s$ are ancestors of $\varphi(s)$. If $t \in T_a$, then $t$ has infinitely many ancestors, so in particular there exists $s \in S$ such that $\varphi(s) = t$. But, all ancestors of $t$, except $s$, are ancestors of $s$ so $s \in S_a$. Hence $\varphi\vert_{S_a}$ is indeed well defined and bijective. 

    Next we claim that $\varphi\vert_{S_b}:S_b\rightarrow T_b$ is bijective. If $s \in S_b$, then $s$'s ancestors terminate in $S$, so $\varphi(s) \in T_b$. If $t \in T_b$, then $t$ has at least one ancestor $s \in S$, and as $\varphi(s) \in T_b$, $s \in S_b$. Thus $\varphi\vert_{S_b}$ is well defined and bijective. Dually, we have that $\psi\vert_{T_c}:T_c\rightarrow S_c$ is bijective. Then define $\Phi:S\rightarrow T$ by $\Phi(s) = \varphi(s)$ for $s \in S_a\cup S_b$, and $\Phi(s) = \psi\vert_{T_c}^{-1}(s)$ for $s \in S_c$, which is by construction bijective.
\end{proof}

A classical application of this result is in the following example:

\begin{example}
    $\text{Card}(\N) = \text{Card}(\N\times \N)$. Define $\varphi:\N\rightarrow \N\times \N$ by $\varphi = \Delta$ is the diagonal, so $\varphi$ is injective. Conversely, define $\psi:\N\times\N\rightarrow \N$ by $\psi(n,m) = 2^n3^m$, so by the fundamental theorem of arithmetic $\psi$ is injective. Then by Schr\"{o}der-Bernstein there exists a bijection $\Phi:\N\rightarrow \N\times \N$, as desired.
\end{example}

The following are the axioms founding the Zermelo-Frankel axioms of set theory with Choice:

\begin{axiom}[ZFC Axioms]\index{ZFC}
    The following constitute the axioms of ZFC: \begin{enumerate}
        \item (Emptyset) There is a set, denoted by $\emptyset$, which has no members: $$\exists x\forall t\;\lnot t \in x$$
        \item (Pairset) For any two sets $x$ and $y$ there is a set $p$ with the property that $t \in p$ if and only if $t = x$ or $t = y$. This set $p$ is usually denoted $\{x,y\}$: $$\forall x\forall y\exists p(t \in p \iff (t = x\lor t = y))$$
        \item (Extensionality) For any two sets $x$ and $y$, $x = y$ if and only if $x$ and $y$ have exactly the same members: $$\forall x\forall y(x = y \iff \forall t(t \in x \iff t \in y))$$
        \item (Union Set) For any set $x$ there exists a set denote by $\bigcup x$ whose members are exactly the members of the members of $x$: $$\forall x \exists y\forall t(t \in y \iff \exists y(y \in x \land t \in y))$$
        \item (Infinity) There exists a set $I$ which contains $0 = \emptyset$ as well as the successor of each of its members; that is, if $x \in I$, then $S(x) := x \cup \{x\} \in I$: $$\exists x(\emptyset \in I \land \forall x(x \in I \implies \bigcup\{x,\{x\}\}))$$
        \item (Powerset) For each set $A$ there exists a set $\mathcal{P}(A)$ whose members are the subsets of $A$: $$\forall x \exists y\forall t(t \in y \iff \forall z(z \in t \implies z \in x))$$
        \item (Separation) Suppose $P$ is a definite condition. For each set $A$ there exists a set $B$ whose members are exactly the members of $A$ that satisfy $P$: $$\forall x \exists y \forall t(t \in B \iff (t \in x \land P(t)))$$
        \item (Replacement) Suppose $P$ is a definite binary condition such that for each set $x$ there is a unique set $y$ for which $P(x,y)$ holds. Given a set $A$ there exists a set $B$ with the property that $y \in B$ if and only if there exists $x \in A$ such that $P(x,y)$: $$\forall x\exists y\forall t(t \in y \iff \exists z(z \in x \land P(z,t)))$$
        \item (Regularity) Every non-empty set $A$ contains an element that is disjoint from $A$: $$\forall x(\lnot x = \emptyset \implies \exists t(t \in x \land \forall y(y \in t\implies \lnot y \in x)))$$
        \item (Choice) Every non-empty set $X$ whose members are all non-empty sets, there exists a function $f:X\rightarrow \bigcup X$ such that $f(A) \in A$ for all $A \in X$.
    \end{enumerate}
\end{axiom}

\begin{lemma}
    If $\varphi:S\rightarrow T$ is onto, then there exists $\psi:T\rightarrow S$ which is injective.
\end{lemma}
\begin{proof}
    Let $\varphi:S\rightarrow T$ be onto. Then let $X = \{\varphi^{-1}(t):t \in T\}$, so $S = \bigcup X$, and all members of $X$ are non-empty sets since $\varphi$ is onto. By the axiom of choice there exists a function $f:X\rightarrow \bigcup X$ such that $f(\varphi^{-1}(t)) \in \varphi^{-1}(t)$ for all $t \in T$. Since $\varphi$ is a well defined function $f$ is injective. Let $g:T\rightarrow X$ by $g(t) = \varphi^{-1}(t)$. Then $g$ is also injective as $\varphi$ is well-defined, so their composite $f\circ g:T\rightarrow \bigcup X = S$ is an injection.
\end{proof} 

As an application of our results, I claim that $\text{Card}(\R)\neq \text{Card}(\N)$:

\begin{proof}
    First, $\iota:(0,1)\rightarrow \R$, being the natural inclusion, is an injection, and $\varphi:\R\rightarrow (0,1)$ given by $\varphi(x) = \frac{e^x}{e^x+1}$ is an injection, so by Schr\"{o}der Bernstein there exists a bijection $\Phi:(0,1)\rightarrow \R$. Towards a contradiction suppose $\text{Card}(\N) = \text{Card}(\R) = \text{Card}((0,1))$, so we have a bijection $f:\N\rightarrow (0,1)$. Expand the terms in their decimal expansion, so $f(j) = \sum_{n=1}^{\infty}a_{jn}10^{-n}$, $a_{jn} \in \{0,1,2,...,9\}$. Define $x$ by $x = \sum_{n=1}^{\infty}b_n10^{-1}$ where $b_n = 2$ if $a_{nn} \neq 2$ and $b_n = 3$ if $a_{nn} = 2$. Thus $x \neq f(j)$ for all $j \in \N$, but by assumption $f$ is bijective, and hence onto, which is a contradiction since $x \in (0,1)$. Thus, no such bijection can exist.
\end{proof}

\begin{definition}
    For sets $S$ and $T$ we define $\leq$ on the cardinals by $\text{Card}(S)\leq \text{Card}(T)$ if and only if there exists an injection $\varphi:S\rightarrow T$, and $\text{Card}(S) < \text{Card}(T)$ if and only if $\text{Card}(S) \leq \text{Card}(T)$ and $\text{Card}(S) \neq \text{Card}(T)$.
\end{definition}

Then it follows that $\text{Card}(\N) < \text{Card}(\R)$. 

\begin{conjecture}[Continuum Hypothesis]\index{Continuum Hypothesis}
    There exists no set with cardinality strictly between $\aleph_0 = \text{Card}(\N)$ and $\aleph_1 = \text{Card}(\R)$.
\end{conjecture}

This hypothesis cannot be proven and taking it to be true or false in your system for set theory leads to no contradictions.

\begin{proposition}
    For any set $S$, $\mathcal{P}(S) \cong 2^S$.
\end{proposition}
\begin{proof}
    Let $\varphi:\mathcal{P}(S)\rightarrow 2^S$ by $\varphi(A)(s) = 1$ if and only if $s \in A$, and $0$ otherwise, for all $A \in \mathcal{P}(S)$. This is an injection, and a surjection as we can take $X_f = \{s \in S: f(s) = 1\}$ for all $f \in 2^S$, so $\varphi(X_f) = f$.
\end{proof}

\begin{proposition}[Cantor's Theorem]\index{Cantor's Theorem}
    For any set $S$, $\text{Card}(S) < \text{Card}(\mathcal{P}(S))$
\end{proposition}
\begin{proof}
    The inclusion $\iota:S\rightarrow \mathcal{P}(S)$ by $\iota(s) = \{s\}$ for all $s \in S$, is an injection so $\text{Card}(S) \leq \text{Card}(\mathcal{P}(S))$. Towards a contradiction we have $f:S\twoheadrightarrow \mathcal{P}(S)$. Let $B = \{s \in S:s \notin f(s)\}$. Then $f(s) = B$ for some $s \in S$. But then $$s \notin B \iff s \notin f(s) \iff s \notin B$$ which is a contradiction, so no such $f$ can exist.
\end{proof}

Due to Cantor's theorem we obtain an infinite chain of infinite cardinals $$\text{Card}(\N) < \text{Card}(\mathcal{P}(\N)) < \text{Card}(\mathcal{P}(\mathcal{P}(\N))) < ...$$
An important, but non-trivial result, is $\text{Card}(\R\times \R) = \text{Card}(\R)$.


